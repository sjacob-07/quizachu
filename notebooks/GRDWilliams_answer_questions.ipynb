{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answering questions using Roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Main solution using roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/george/Documents/LeWagon/Transformers_Hugging_Face\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting pytesseract\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Using cached huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2023.12.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch)\n",
      "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from pytesseract) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Using cached huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "Downloading fsspec-2023.12.0-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.9/168.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, tqdm, sympy, safetensors, regex, pytesseract, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch\n",
      "Successfully installed filelock-3.13.1 fsspec-2023.12.0 huggingface-hub-0.19.4 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 pytesseract-0.3.10 regex-2023.10.3 safetensors-0.4.1 sympy-1.12 tokenizers-0.15.0 torch-2.1.1 tqdm-4.66.1 transformers-4.35.2 triton-2.1.0\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: regex in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from sacremoses) (2023.10.3)\n",
      "Collecting click (from sacremoses)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from sacremoses) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /home/george/.pyenv/versions/3.10.6/envs/quizachu/lib/python3.10/site-packages (from sacremoses) (4.66.1)\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, click, sacremoses\n",
      "Successfully installed click-8.1.7 sacremoses-0.1.1 sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Install requirements\"\"\"\n",
    "# Install the transformers library from HuggingFace\n",
    "!pip install transformers torch pytesseract\n",
    "# You'll also need some extra tools that some of these models use under the hood\n",
    "! pip install sentencepiece sacremoses\n",
    "# to read pdf\n",
    "!pip install pdfquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Import packages\"\"\"\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"Import our question answering model\"\"\"\n",
    "question_answerer = pipeline(model = 'deepset/roberta-base-squad2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_questions_with_confidence(context = \"You did not specify any content\", questions = [\"Did you mean to specify a question?\"]):\n",
    "    \"\"\"Takes a list called 'questions' that contains the questions to answer\n",
    "    Takes some text called 'content' as a source for answering questions\n",
    "    Returns a dataframe of the questions with their answers and an assessment of confidence in the answers\n",
    "    If no context or content is provided, returns a dataframe requesting these\"\"\"\n",
    "    \n",
    "    # List to fill with questions, answers, and confidence\n",
    "    questions_answers = []\n",
    "    \n",
    "    # For each question create an empty dictionary and call the question_answerer model on the question\n",
    "    for q in questions: \n",
    "        q_a_dict = {}\n",
    "        q_a = question_answerer(question=q, context=context)\n",
    "        \n",
    "        # Assign the question, and outputs of the question_answerer model to the dictionary\n",
    "        q_a_dict['confidence'] = q_a['score']\n",
    "        q_a_dict['question'] = q\n",
    "        q_a_dict['answer'] = q_a['answer'].replace('\\n', ' ')\n",
    "        \n",
    "        # Add the dictionary to the list and then convert the final list of dicts to a dataframe\n",
    "        questions_answers.append(q_a_dict) \n",
    "    questions_answers = pd.DataFrame(questions_answers)\n",
    "    \n",
    "    # Set a large maxcolwidth to allow for potentially long answers\n",
    "    pd.options.display.max_colwidth = 20000\n",
    "    \n",
    "    return questions_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_n_questions(context, questions, c = 0.5, n = 5):\n",
    "    \"\"\"Selects the top n questions with the highest confidence level c\n",
    "    User can define how many questions are required and the minimum confidence level\"\"\"\n",
    "    \n",
    "    # Call answer_questions to get a df of questions and answers\n",
    "    questions_answers = answer_questions_with_confidence(context, questions)\n",
    "    \n",
    "    # Filter for confidence\n",
    "    conf_questions = questions_answers[questions_answers['confidence'] > c] \n",
    "    \n",
    "    # Return n questions ordered by confidence\n",
    "    selected_questions = conf_questions.sort_values(by='confidence', ascending=False).head(n)\\\n",
    "    .reset_index().rename(columns={'index':'original_question_number'}) \n",
    "    \n",
    "    \"\"\"Check whether enough questions can be returned and explain why if not\"\"\"\n",
    "    \n",
    "    # Were enough questions generated?\n",
    "    if len(questions_answers) < n:\n",
    "        print(f\"Only {len(questions_answers)} questions were generated\")\n",
    "        \n",
    "        # Did enough questions meet the confidence requirement?\n",
    "        if len(selected_questions) == 0:\n",
    "            print(\"No questions met your required confidence level.\")\n",
    "        elif len(selected_questions) < n: \n",
    "            print(f\"Not enough questions met your required confidence level,\\\n",
    " but here {'is' if len(selected_questions) == 1 else 'are'} the {len(selected_questions)} that did:\")\n",
    "        else:\n",
    "            print(f\"Here are your {n} questions\")\n",
    "            \n",
    "    else:\n",
    "        # Did enough questions meet the confidence requirement?\n",
    "        if len(selected_questions) == 0:\n",
    "            print(\"No questions met your required confidence level.\")\n",
    "        elif len(selected_questions) < n: \n",
    "            print(f\"Not enough questions met your required confidence level,\\\n",
    " but here {'is' if len(selected_questions) == 1 else 'are'} the {len(selected_questions)} that did:\")\n",
    "        else:\n",
    "            print(f\"Here are your {n} questions\")\n",
    "            \n",
    "    return selected_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = pipeline(model = 'deepset/roberta-base-squad2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "\n",
    "tokens = tokenizer.encode(\"This is easy!\", return_tensors = \"tf\")\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"deepset/roberta-base-squad2\", from_pt = True)\n",
    "\n",
    "output_tokens = model.generate(tokens)\n",
    "\n",
    "print(output_tokens)\n",
    "\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Open a pdf file as a possible source of context\"\"\"\n",
    "from pdfquery import PDFQuery\n",
    "\n",
    "pdf = PDFQuery('/home/george/Downloads/intelligent_M_and_A.pdf')\n",
    "pdf.load()\n",
    "\n",
    "# Use CSS-like selectors to locate the elements\n",
    "text_elements = pdf.pq('LTTextLineHorizontal')\n",
    "\n",
    "# Extract the text from the elements\n",
    "text = [t.text for t in text_elements]\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Open a text file as a possible source of context\"\"\"\n",
    "file = open(\"/home/george/Documents/example_article.txt\", \"r\") # Example file\n",
    "content = file.read()\n",
    "print(content)\n",
    "file.close()\n",
    "\n",
    "question = ['Where is Spain?'] # Example question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Extract text using OCR\n",
    "This works with images obtained from the snipping tool.\n",
    "This works with photographs of text but images need to be rotated to ensure they are the correct way up.\n",
    "It does not recognise handwriting.\"\"\"\n",
    "\n",
    "# \"\"\"For \"\"\"\n",
    "# !sudo apt install tesseract-ocr  \n",
    "# !sudo apt install libtesseract-dev\n",
    "# !pip install Pillow pytesseract\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def ocr_document(image_path):\n",
    "    # Open the image using the Pillow library\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Perform OCR using Tesseract\n",
    "    text = pytesseract.image_to_string(image)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Result:\n",
      "The startup’s flagship product, Pillow Talk, allows you to\n",
      "connect to a loved one when you are unable to be in the same\n",
      "place as them, all through the sound and feel of their heartbeat.\n",
      "\n",
      "I ittle Riot make technology that facilitates human connection.\n",
      "\n",
      "So how does it work? As a pair, each of you get a wristband to wear\n",
      "to bed and a small speaker that should be placed under your pillow.\n",
      "The wristband picks up your real-time heartbeat and sends it to the\n",
      "other person's pillow. In your own pillow, you can hear the heartbeat\n",
      "of your loved one, wherever in the world you each may be.\n",
      "\n",
      "What started as a project at university, turned into the well-loved\n",
      "Pillow Talk product which is now used in over 70 countries across\n",
      "the globe.\n",
      "\n",
      "Having won the ‘Biggest 2020 Hero’ award at Startup Magazine's first\n",
      "ever Hustle Awards, we thought it was about time to check in with\n",
      "Founder Joanna Montgomery to see what's new, where the startup is\n",
      "now, and find out about the last few years.\n",
      "\n",
      "HOW HAS THE LAST FEW YEARS BEEN FOR\n",
      "LITTLE RIOT?\n",
      "\n",
      "The company has now been in existence for around 13 years. The\n",
      "R&D journey for Little Riot was a long one, launching in 2015 and\n",
      "originally shipping in 2017. In the last few years, the company has\n",
      "remained successful, continuing its journey facilitating human\n",
      "connection.\n",
      "\n",
      "Since last speaking to Little Riot, there has been an entire global\n",
      "pandemic. COVID became a sink or swim situation for many\n",
      "\n",
      " \n",
      "\n",
      "startups and Little Riot managed to not only swim, but succeed due\n",
      "\n",
      "to the isolation we were all put through.\n",
      "\n",
      "“COVID was huge for us. It was obviously unfortunate that it took a\n",
      "global pandemic for the world to realise the real value in what we're\n",
      "building and what I've been banging on about for like, seven/eight\n",
      "years prior. I just felt like video calls were not good enough in terms\n",
      "of technology that connects you with someone you love when you\n",
      "can't be with them,” commented Montgomery.\n",
      "\n",
      "PILLOW TALK IN HOSPITALS\n",
      "\n",
      "When Startups last spoke to Montgomery, the company was about\n",
      "\n",
      "to start trials of Pillow Talk in hospitals, and this was completely\n",
      "\n",
      "fast tracked because of the pandemic. “We'd started doing a few\n",
      "pilots in children's hospitals, so connecting parents with their kids\n",
      "in intensive care, then obviously, during COVID, so many people\n",
      "were hospitalised, and nobody could have visitors. So, we saw a huge\n",
      "increase in hospitals using it and we accelerated the pivot more into\n",
      "the medical space”\n",
      "\n",
      "Pillow Talk as a consumer product is being used in around 70\n",
      "countries worldwide, and in hospitals this is mainly focused on\n",
      "Europe, the US, and some in the far east. Montgomery explained:\n",
      "“We still get a lot of organic inbound inquiries from hospitals, and\n",
      "palliative care is a big one. It's really rewarding as a Founder, having\n",
      "worked in something for 13 years, to see it being used in situations\n",
      "that make so much difference to someone's life. When you see It\n",
      "being used in a hospital between a child in intensive care and their\n",
      "parents makes me feel like I could walk outside and get hit by a bus\n",
      "\n",
      "3 Writer: Anna Wood\n",
      "Startups Magazine\n",
      "\n",
      " \n",
      " \n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path = '/home/george/Downloads/articletoocrquizachu/big.jpg'\n",
    "result_text = ocr_document(image_path)\n",
    "\n",
    "print(\"OCR Result:\")\n",
    "print(result_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Import packages\"\"\"\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject of the Ai project\n",
      "\n",
      "\n",
      "Ai\n",
      "Species\n",
      "chimpanzee\n",
      "Born\n",
      "c.\n",
      " 1976\n",
      " (age \n",
      "46–47)\n",
      "Guinean Forests of West Africa\n",
      "Offspring\n",
      "Ayumu (chimpanzee)\n",
      "\n",
      "\n",
      "Ai\n",
      " (born in 1976, estimated) is a female \n",
      "western chimpanzee\n",
      " (\n",
      "Pan troglodytes verus\n",
      "),\n",
      "[1]\n",
      " currently living at the \n",
      "Primate Research Institute\n",
      " of \n",
      "Kyoto University\n",
      " (acronym KUPRI). She is the first subject of the \n",
      "Ai project\n",
      ", a research program started in 1978 by Kiyoko Murofushi and \n",
      "Tetsuro Matsuzawa\n",
      " which is aimed at understanding chimpanzee \n",
      "cognition\n",
      " through computer interface experiments.\n",
      "[2]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Biography\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "Ai was born in 1976 (estimated), in the \n",
      "Guinean Forests of West Africa\n",
      ".\n",
      "[1]\n",
      " Born wild, Ai was soon taken into captivity and sold to KUPRI in 1977 by an animal trader (this type of sale became illegal in 1980 with \n",
      "Japan\n",
      "'s ratification of \n",
      "CITES\n",
      ").\n",
      "[1]\n",
      "  She was the first subject of KUPRI’s chimpanzee project, which was intended to become Japan’s first ape-language study in the vein of earlier ape-language studies.\n",
      "[2]\n",
      " Ai was joined at KUPRI the following year by two more chimpanzees, Akira and Mari.\n",
      "[3]\n",
      " In 2000, Ai gave birth to a son, \n",
      "Ayumu\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "Ai Project\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "Matsuzawa has written that the difference between the Ai Project and earlier ape-language studies is that he was less interested in seeing if Ai and the other chimpanzees were capable of learning some degree of human language than trying to understand how chimpanzees perceive their surroundings.\n",
      "[2]\n",
      " To study this, the research team created a unique keyboard through which Ai and the other chimpanzees at KUPRI could interact with a computer –– the computer was used to standardize the studies and reduce variation that might be introduced by human researchers, and because the mechanism could be easily used in comparative studies on humans.\n",
      "[1]\n",
      " With this method, researchers have studied Ai’s memory, number-learning, and perception of color. Matsuzawa wrote that Ai was “the first chimpanzee who learned to use Arabic numerals to represent numbers,” and her ordering of different shades and hues of \n",
      "Munsell color chips\n",
      " was similar to human orderings.\n",
      "[2]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group and living quarters\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "In 2000, not long after the birth of three chimpanzees, Ai's group numbered 15;\n",
      "[1]\n",
      " in 2010, there were 14 members.\n",
      "[4]\n",
      " This is similar to the size of some small chimpanzee groups in the wild, where in some places with stable food supplies group size hovers at around 20 chimpanzees.\n",
      "[5]\n",
      " Matsuzawa has attempted to blend elements of laboratory and field research, and KUPRI has an outdoor complex for the chimpanzees called the Ape Research Annex, built in 1995, with an 8-meter tall tower, a river, and trees.\n",
      "[3]\n",
      "\n",
      "\n",
      "\n",
      "After Ai gave birth to her son, Ayumu, in 2000, they were placed in a “twin booth” where Ayumu could live with Ai in one booth but also be exposed to the researcher in the other booth every day, making the researcher an integral part of Ayumu’s life and studying him in front of Ai, with her implicit approval.\n",
      "[6]\n",
      " Matsuzawa wrote that:\n",
      "Two almost identical booths are placed side by side. There is a door between the two booths that can alternately be opened to connect the two areas, closed to separate the two individuals, or positioned half-open to allow the young chimpanzee to crawl from one area to the other while preventing the mother chimpanzee from entering the neighboring booth.\n",
      "[6]\n",
      "This method allowed the research team to consistently track Ayumu's development without interfering excessively with the mother-offspring relationship.\n",
      "\n",
      "Art\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "Ai loves to paint and draw –– she started drawing at a young age –– and is often brought art materials for free-drawing or painting.\n",
      "[6]\n",
      " She creates art as an end in itself, without a food reward. In 2013 she made a painting that was given to the president of Kyoto University; later, in honor of the 40th anniversary of her arrival at KUPRI, this painting was made into a silk scarf and given as a gift to \n",
      "Jane Goodall\n",
      ".\n",
      "[6]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "See also\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "Primate Research Institute\n",
      "\n",
      "\n",
      "Great ape language\n",
      "\n",
      "\n",
      "List of individual apes\n",
      "\n",
      "\n",
      "References\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^ \n",
      "a\n",
      " \n",
      "b\n",
      " \n",
      "c\n",
      " \n",
      "d\n",
      " \n",
      "e\n",
      " \n",
      "Matsuzawa, Tetsuro (2003-12-01). \n",
      "\"The Ai project: historical and ecological contexts\"\n",
      ". \n",
      "Animal Cognition\n",
      ". \n",
      "6\n",
      " (4): 199–211. \n",
      "doi\n",
      ":\n",
      "10.1007/s10071-003-0199-2\n",
      ". \n",
      "ISSN\n",
      " \n",
      "1435-9448\n",
      ". \n",
      "PMID\n",
      " \n",
      "14566577\n",
      ". \n",
      "S2CID\n",
      " \n",
      "8928490\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^ \n",
      "a\n",
      " \n",
      "b\n",
      " \n",
      "c\n",
      " \n",
      "d\n",
      " \n",
      "Matsuzawa, Tetsuro (October 2009). \n",
      "\"The chimpanzee mind: in search of the evolutionary roots of the human mind\"\n",
      ". \n",
      "Animal Cognition\n",
      ". \n",
      "12\n",
      " (S1): S1-9. \n",
      "doi\n",
      ":\n",
      "10.1007/s10071-009-0277-1\n",
      ". \n",
      "ISSN\n",
      " \n",
      "1435-9448\n",
      ". \n",
      "PMID\n",
      " \n",
      "19727864\n",
      ". \n",
      "S2CID\n",
      " \n",
      "7028415\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^ \n",
      "a\n",
      " \n",
      "b\n",
      " \n",
      "\"Ai | Chimpanzee Ai | Primate Research Institute, Kyoto University\"\n",
      ". \n",
      "langint.pri.kyoto-u.ac.jp\n",
      ". Retrieved \n",
      "2020-10-24\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^\n",
      " \n",
      "\"Thinking Like a Chimpanzee\"\n",
      ". \n",
      "Smithsonian Magazine\n",
      ". Retrieved \n",
      "2020-10-24\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^\n",
      " \n",
      "Neal Webb, Sarah J.; Hau, Jann; Schapiro, Steven J. (January 2019). \n",
      "\"Does group size matter? Captive chimpanzee ( Pan troglodytes ) behavior as a function of group size and composition\"\n",
      ". \n",
      "American Journal of Primatology\n",
      ". \n",
      "81\n",
      " (1): e22947. \n",
      "doi\n",
      ":\n",
      "10.1002/ajp.22947\n",
      ". \n",
      "PMC\n",
      " \n",
      "6472487\n",
      ". \n",
      "PMID\n",
      " \n",
      "30620093\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^ \n",
      "a\n",
      " \n",
      "b\n",
      " \n",
      "c\n",
      " \n",
      "d\n",
      " \n",
      "Matsuzawa, Tetsuro (April 2017). \n",
      "\"The 40th anniversary of the Ai Project: the commemorative gift is a silk scarf painted by Ai the chimpanzee\"\n",
      ". \n",
      "Primates\n",
      ". \n",
      "58\n",
      " (2): 261–265. \n",
      "doi\n",
      ":\n",
      "10.1007/s10329-017-0604-0\n",
      ". \n",
      "ISSN\n",
      " \n",
      "0032-8332\n",
      ". \n",
      "PMID\n",
      " \n",
      "28293756\n",
      ". \n",
      "S2CID\n",
      " \n",
      "3635041\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "External links\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "Ai's \n",
      "Official website\n",
      "\n",
      "\n",
      "v\n",
      "t\n",
      "e\n",
      "Notable non-human \n",
      "apes\n",
      "List of individual apes\n",
      "List of individual monkeys\n",
      "Monkeys and apes in space\n",
      "List of fictional primates\n",
      "Bonobos\n",
      "\n",
      "\n",
      "Kanzi\n",
      "\n",
      "\n",
      "Nyota\n",
      "\n",
      "\n",
      "Panbanisha\n",
      "\n",
      "\n",
      "Chimpanzees\n",
      "\n",
      "\n",
      "Ai\n",
      "\n",
      "\n",
      "Ayumu\n",
      "\n",
      "\n",
      "Azalea\n",
      "\n",
      "\n",
      "Bonzo\n",
      "\n",
      "\n",
      "Pierre Brassau\n",
      "\n",
      "\n",
      "Bubbles\n",
      "\n",
      "\n",
      "Cheeta\n",
      "\n",
      "\n",
      "Congo\n",
      "\n",
      "\n",
      "Enos\n",
      "\n",
      "\n",
      "Gregoire\n",
      "\n",
      "\n",
      "Gua\n",
      "\n",
      "\n",
      "Ham\n",
      "\n",
      "\n",
      "Jiggs\n",
      "\n",
      "\n",
      "Jimmy\n",
      "\n",
      "\n",
      "Jinx\n",
      "\n",
      "\n",
      "Jo Mendi II\n",
      "\n",
      "\n",
      "Julius\n",
      "\n",
      "\n",
      "Kasakela chimpanzee community\n",
      "\n",
      "\n",
      "Kokomo Jr.\n",
      "\n",
      "\n",
      "Lana\n",
      "\n",
      "\n",
      "Little Mama\n",
      "\n",
      "\n",
      "Loulis\n",
      "\n",
      "\n",
      "Lucy\n",
      "\n",
      "\n",
      "Macaco Tião\n",
      "\n",
      "\n",
      "Marquis Chimps\n",
      "\n",
      "\n",
      "Mitumba chimpanzee community\n",
      "\n",
      "\n",
      "Moja\n",
      "\n",
      "\n",
      "J. Fred Muggs\n",
      "\n",
      "\n",
      "Nim Chimpsky\n",
      "\n",
      "\n",
      "Oliver\n",
      "\n",
      "\n",
      "Pankun\n",
      "\n",
      "\n",
      "Panpanzee\n",
      "\n",
      "\n",
      "Sami\n",
      "\n",
      "\n",
      "Santino\n",
      "\n",
      "\n",
      "Sarah\n",
      "\n",
      "\n",
      "Sultan\n",
      "\n",
      "\n",
      "Travis\n",
      "\n",
      "\n",
      "Viki\n",
      "\n",
      "\n",
      "Washoe\n",
      "\n",
      "\n",
      "Gorillas\n",
      "\n",
      "\n",
      "Alfred the Gorilla\n",
      "\n",
      "\n",
      "Babec\n",
      "\n",
      "\n",
      "Binti Jua\n",
      "\n",
      "\n",
      "Bobo\n",
      "\n",
      "\n",
      "Bokito\n",
      "\n",
      "\n",
      "Charles the Gorilla\n",
      "\n",
      "\n",
      "Colo\n",
      "\n",
      "\n",
      "Fatou\n",
      "\n",
      "\n",
      "Gargantua\n",
      "\n",
      "\n",
      "Guy the Gorilla\n",
      "\n",
      "\n",
      "Harambe\n",
      "\n",
      "\n",
      "Ivan\n",
      "\n",
      "\n",
      "Jambo\n",
      "\n",
      "\n",
      "Jenny\n",
      "\n",
      "\n",
      "John Daniel\n",
      "\n",
      "\n",
      "Jumoke\n",
      "\n",
      "\n",
      "Koko\n",
      "\n",
      "\n",
      "Kokomo\n",
      "\n",
      "\n",
      "Louis\n",
      "\n",
      "\n",
      "Massa\n",
      "\n",
      "\n",
      "Max\n",
      "\n",
      "\n",
      "Michael\n",
      "\n",
      "\n",
      "Nico\n",
      "\n",
      "\n",
      "Ndume\n",
      "\n",
      "\n",
      "Ozzie\n",
      "\n",
      "\n",
      "Pattycake\n",
      "\n",
      "\n",
      "Pogo\n",
      "\n",
      "\n",
      "Samson\n",
      "\n",
      "\n",
      "Shabani\n",
      "\n",
      "\n",
      "Snowflake\n",
      "\n",
      "\n",
      "Timmy\n",
      "\n",
      "\n",
      "Titus\n",
      "\n",
      "\n",
      "Trudy\n",
      "\n",
      "\n",
      "Toto\n",
      "\n",
      "\n",
      "Willie B.\n",
      "\n",
      "\n",
      "Orangutans\n",
      "\n",
      "\n",
      "Abang\n",
      "\n",
      "\n",
      "Ah Meng\n",
      "\n",
      "\n",
      "Azy\n",
      "\n",
      "\n",
      "Bonnie\n",
      "\n",
      "\n",
      "Chantek\n",
      "\n",
      "\n",
      "Jenny\n",
      "\n",
      "\n",
      "Joe Martin\n",
      "\n",
      "\n",
      "Karen\n",
      "\n",
      "\n",
      "Karta\n",
      "\n",
      "\n",
      "Ken Allen\n",
      "\n",
      "\n",
      "Manis\n",
      "\n",
      "\n",
      "Nonja (Austria)\n",
      "\n",
      "\n",
      "Nonja (Malaysia)\n",
      "\n",
      "\n",
      "Sam\n",
      "\n",
      "\n",
      "Sandra\n",
      "\n",
      "\n",
      "Tonda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieved from \"\n",
      "https://en.wikipedia.org/w/index.php?title=Ai_(chimpanzee)&oldid=1178197952\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Scrape Wikipedia as a possible source of context\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_wikipedia_article(url):\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the main article text (adjust the selector based on the structure of the webpage)\n",
    "        article_text = soup.find('div', {'id': 'mw-content-text'}).get_text(separator='\\n')\n",
    "        \n",
    "        return article_text\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "url = 'https://en.wikipedia.org/wiki/Ai_(chimpanzee)'\n",
    "wikipedia_article_text = scrape_wikipedia_article(url)\n",
    "\n",
    "if wikipedia_article_text:\n",
    "    print(wikipedia_article_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat whose pictures went viral for regularly visiting a railway station is releasing a Christmas single. Four-year-old Nala has been delighting commuters who have been taking photos of her at Stevenage station. Owner Natasha Ambler revealed the cat was releasing a single called Meow and has been approached for a book deal. The ginger tabby has also recorded a video for the song due to be released this week, under the name Nala the Station Cat. It has been produced by Danny Kirsch, who wrote it with Joe Killington, while Nala is also co-credited as a songwriter, as well as a vocalist. Ms Ambler said \"we want to spread the happiness that Stevenage has had, and she's had on socials to the world\". The single is officially released on Wednesday and BBC Three Counties Radio's Justin Dealey gave the single an exclusive first play on Sunday. \"I'm slightly lost for words,\" said the presenter after the song finished. Nala's owner replied: \"So am I to be fair.\" The musical cat does not yet have an agent and her owner said \"we're all doing our emails ourselves; it's quite new to us\". \"We'll start small and hopefully she gets in the charts, but number one would be fantastic,\" she added. Charity campaigners LadBaby have filled the coveted Christmas number one single spot every year for the last five years. All proceeds from the single will be donated to the RSPCA and Stevenage homelessness charity Feed Up Warm Up. The music video, filmed at Stevenage railway station, will be unveiled before Christmas. Follow East of England news on Facebook, Instagram and X. Got a story? Email eastofenglandnews@bbc.co.uk or WhatsApp 0800 169 1830\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Scrape BBC as a possible source of context\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_bbc_article(url):\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the main article text (adjust the selector based on the structure of the webpage)\n",
    "        article = []\n",
    "        for para in soup.find_all(\"div\", {\"data-component\": \"text-block\"}):\n",
    "            article.append(para.text)\n",
    "        article_text = \" \".join(article)\n",
    "        \n",
    "        return article_text\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example usage - cat article\n",
    "url = 'https://www.bbc.co.uk/news/uk-england-beds-bucks-herts-67407334'\n",
    "bbc_article_text = scrape_bbc_article(url).replace('\\n', ' ')\n",
    "\n",
    "if bbc_article_text:\n",
    "    print(bbc_article_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Importing audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Installs to analyse audio\"\"\"\n",
    "!sudo apt install ffmpeg\n",
    "!pip3 install datasets\n",
    "!pip install SoundFile\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Example audio to analyse\"\"\"\n",
    "!mkdir data\n",
    "!curl https://wagon-public-datasets.s3.amazonaws.com/deep_learning_datasets/harvard.wav > data/harvard.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Packages for audio\"\"\"\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Read the audio file and play it to verify\"\"\"\n",
    "rate, audio = wavfile.read(\"data/harvard.wav\")\n",
    "Audio(audio.T, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Transcription of a downloaded wav file\"\"\"\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import librosa  \n",
    "\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "model.config.forced_decoder_ids = None\n",
    "\n",
    "# Whisper requires a sampling rate of 16000 so must convert this with librosa\n",
    "audio, rate = librosa.load('data/harvard.wav', sr=16000)\n",
    "input_features = processor(audio, sampling_rate=rate, return_tensors=\"pt\").input_features \n",
    "\n",
    "# generate token ids\n",
    "predicted_ids = model.generate(input_features)\n",
    "# decode token ids to text\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)\n",
    "\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Transcription of a flac file from hugging face\"\"\"\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "model.config.forced_decoder_ids = None\n",
    "\n",
    "# load dummy dataset and read audio files\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "sample = ds[0][\"audio\"]\n",
    "input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features \n",
    "\n",
    "# generate token ids\n",
    "predicted_ids = model.generate(input_features)\n",
    "# decode token ids to text\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)\n",
    "\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Reading handwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This works well for single lines of handwriting but does not support multiple lines.\n",
    "I need to split multiple line files into single lines.\"\"\"\n",
    "\n",
    "hw = pipeline(model = 'microsoft/trocr-base-handwritten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved line 1 to /home/george/Downloads/split_text/line_1.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This attempts to split images. It is the first time I gave up and got chatgpt to write code for me.\n",
    "It does not work very well - it identifies words but does not link them correctly as lines.\"\"\"\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pytesseract\n",
    "\n",
    "def split_and_save_handwritten_lines(image_path, output_directory):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use adaptive thresholding to preprocess the image\n",
    "    _, binary_image = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # List to store individual line images\n",
    "    line_images = []\n",
    "\n",
    "    # Minimum width and height threshold for a contour to be considered a line\n",
    "    min_width_threshold = 300\n",
    "    min_height_threshold = 20\n",
    "\n",
    "    # Iterate through contours\n",
    "    for i, contour in enumerate(contours):\n",
    "        # Get bounding box for each contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Filter out contours based on width and height\n",
    "        if w > min_width_threshold and h > min_height_threshold:\n",
    "            # Crop the original image to extract the line\n",
    "            line_image = image[y:y+h, x:x+w]\n",
    "\n",
    "            # Save the line image to the output directory\n",
    "            output_path = os.path.join(output_directory, f'line_{i+1}.png')\n",
    "            cv2.imwrite(output_path, line_image)\n",
    "\n",
    "            # Append the line image to the list\n",
    "            line_images.append(line_image)\n",
    "\n",
    "    return line_images\n",
    "\n",
    "# Example usage\n",
    "image_path = '/home/george/Downloads/Handwriting-Y4.png'\n",
    "output_directory = '/home/george/Downloads/split_text'\n",
    "lines = split_and_save_handwritten_lines(image_path, output_directory)\n",
    "\n",
    "# Print the paths of saved line images\n",
    "for i, line_image in enumerate(lines, start=1):\n",
    "    print(f\"Saved line {i} to {os.path.join(output_directory, f'line_{i}.png')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.7278719544410706,\n",
       "  'answer': 'Calculating the size of an object',\n",
       "  'start': 0,\n",
       "  'end': 5}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Question-answer format\"\"\"\n",
    "ocr(image='/home/george/Downloads/magnification.jpg',question=\"What does this page say?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Text in more complex layouts, eg invoices or posters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"First model - this answers questions about documents\n",
    "- this works for very simple documents \n",
    "but struggles for anything which implies relationships (e.g. two text boxes that relate to one another)\"\"\"\n",
    "ocr = pipeline(model = 'impira/layoutlm-invoices') #This struggles to find relationships between objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tested distilbert to see if quicker. Some gains but less accurate\"\"\"\n",
    "\"\"\"In tests, 2 means distilbert passed, 1 means roberta passed\"\"\"\n",
    "question_answerer2 = pipeline(model = 'distilbert-base-uncased-distilled-squad') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Underground questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underground_context = \"\"\"The history of the London Underground began in the 19th century with the construction of the Metropolitan Railway,\n",
    "the world's first underground railway. The Metropolitan Railway, which opened in 1863 using gas-lit wooden carriages hauled by steam \n",
    "locomotives, worked with the District Railway to complete London's Circle line in 1884. Both railways expanded, the Metropolitan eventually \n",
    "extending as far as Verney Junction in Buckinghamshire, more than 50 miles (80 km) from Baker Street and the centre of London. \n",
    "The first deep-level tube line, the City and South London Railway, opened in 1890 with electric trains. \n",
    "This was followed by the Waterloo & City Railway in 1898, the Central London Railway in 1900, and the Great Northern and City Railway \n",
    "in 1904. The Underground Electric Railways Company of London (UERL) was established in 1902 to fund the electrification of the \n",
    "District Railway and to complete and operate three tube lines, the Baker Street and Waterloo Railway, the Charing Cross, Euston and \n",
    "Hampstead Railway and the Great Northern, Piccadilly and Brompton Railway, which opened in 1906–07. By 1907 the District and \n",
    "Metropolitan Railways had electrified the underground sections of their lines.\n",
    "\n",
    "Under a joint marketing agreement between most of the companies in the early years of the 20th century, UNDERGROUND signs appeared \n",
    "outside stations in central London. World War I delayed extensions of the Bakerloo and Central London Railways, and people used the \n",
    "tube stations as shelters during Zeppelin air raids by June 1915. After the war, government-backed financial guarantees were used to \n",
    "expand the network, and the tunnels of the City and South London and Charing Cross, Euston and Hampstead Railways were linked at Euston and \n",
    "Kennington, although the combined service was not named the Northern line until later. The Piccadilly line was extended north to \n",
    "Cockfosters and took over District line branches to Harrow (later Uxbridge) and Hounslow. In 1933, the underground railways and all London \n",
    "area tram and bus operators were merged into the London Passenger Transport Board (LPTB). The outlying branches of the Metropolitan were \n",
    "closed; various upgrades were planned. The Bakerloo line's extension to take over the Metropolitan's Stanmore branch, and extensions of \n",
    "the Central and Northern lines, formed part of the 1930s New Works Programme. The outbreak of World War II in 1939 halted or interrupted \n",
    "some of this work, and many tube stations were used as air-raid shelters. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underground_questions = [\"In what year did the London Underground begin?\", # 1963\n",
    "\"In what year did the UERL begin to be built?\", # 1902 - 2, 1\n",
    "\"In what year did the London Underground begin?\",\n",
    "\"What railway line was built in the 18th century?\",\n",
    "\"In what year did the Thames & City Railway open?\",\n",
    "\"How many kilometers long did it take to travel through London's Station?\",\n",
    "\"When did the London Underground first operate?\",\n",
    "\"In what year was the London Underground Station opened?\",\n",
    "\"How many kilometers long was the London Underground Station?\",\n",
    "\"In what year did the Thames & City Railway open?\",\n",
    "\"What railway line was built in London in the 18th century?\",\n",
    "\"What railway line was built in the London Underground?\",\n",
    "\"When did the UERL begin to run through the London Underground?\",\n",
    "\"When did the London Underground begin?\",\n",
    "\"What was the name of the first railway station in London?\",\n",
    "\"In what year did the London Underground begin?\",\n",
    "\"In what year was the London Underground Station closed?\",\n",
    "\"What railway line opened in 1880?\",\n",
    "\"What railway line was built in London in 1880?\",\n",
    "\"What railway line was built in the 18th century?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.930403</td>\n",
       "      <td>In what year did the London Underground begin?</td>\n",
       "      <td>1933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.996830</td>\n",
       "      <td>In what year did the UERL begin to be built?</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930403</td>\n",
       "      <td>In what year did the London Underground begin?</td>\n",
       "      <td>1933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.549939</td>\n",
       "      <td>What railway line was built in the 18th century?</td>\n",
       "      <td>Metropolitan Railway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.881689</td>\n",
       "      <td>In what year did the Thames &amp; City Railway open?</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.771743</td>\n",
       "      <td>How many kilometers long did it take to travel through London's Station?</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.830885</td>\n",
       "      <td>When did the London Underground first operate?</td>\n",
       "      <td>1933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.914037</td>\n",
       "      <td>In what year was the London Underground Station opened?</td>\n",
       "      <td>1933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.794559</td>\n",
       "      <td>How many kilometers long was the London Underground Station?</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.881689</td>\n",
       "      <td>In what year did the Thames &amp; City Railway open?</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.574865</td>\n",
       "      <td>What railway line was built in London in the 18th century?</td>\n",
       "      <td>Metropolitan Railway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.589890</td>\n",
       "      <td>What railway line was built in the London Underground?</td>\n",
       "      <td>Metropolitan Railway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.691294</td>\n",
       "      <td>When did the UERL begin to run through the London Underground?</td>\n",
       "      <td>1933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.509348</td>\n",
       "      <td>When did the London Underground begin?</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.081107</td>\n",
       "      <td>What was the name of the first railway station in London?</td>\n",
       "      <td>Bakerloo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.930403</td>\n",
       "      <td>In what year did the London Underground begin?</td>\n",
       "      <td>1933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.963584</td>\n",
       "      <td>In what year was the London Underground Station closed?</td>\n",
       "      <td>1933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.043353</td>\n",
       "      <td>What railway line opened in 1880?</td>\n",
       "      <td>The Piccadilly line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.241496</td>\n",
       "      <td>What railway line was built in London in 1880?</td>\n",
       "      <td>Metropolitan Railway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.549939</td>\n",
       "      <td>What railway line was built in the 18th century?</td>\n",
       "      <td>Metropolitan Railway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    confidence  \\\n",
       "0     0.930403   \n",
       "1     0.996830   \n",
       "2     0.930403   \n",
       "3     0.549939   \n",
       "4     0.881689   \n",
       "5     0.771743   \n",
       "6     0.830885   \n",
       "7     0.914037   \n",
       "8     0.794559   \n",
       "9     0.881689   \n",
       "10    0.574865   \n",
       "11    0.589890   \n",
       "12    0.691294   \n",
       "13    0.509348   \n",
       "14    0.081107   \n",
       "15    0.930403   \n",
       "16    0.963584   \n",
       "17    0.043353   \n",
       "18    0.241496   \n",
       "19    0.549939   \n",
       "\n",
       "                                                                    question  \\\n",
       "0                             In what year did the London Underground begin?   \n",
       "1                               In what year did the UERL begin to be built?   \n",
       "2                             In what year did the London Underground begin?   \n",
       "3                           What railway line was built in the 18th century?   \n",
       "4                           In what year did the Thames & City Railway open?   \n",
       "5   How many kilometers long did it take to travel through London's Station?   \n",
       "6                             When did the London Underground first operate?   \n",
       "7                    In what year was the London Underground Station opened?   \n",
       "8               How many kilometers long was the London Underground Station?   \n",
       "9                           In what year did the Thames & City Railway open?   \n",
       "10                What railway line was built in London in the 18th century?   \n",
       "11                    What railway line was built in the London Underground?   \n",
       "12            When did the UERL begin to run through the London Underground?   \n",
       "13                                    When did the London Underground begin?   \n",
       "14                 What was the name of the first railway station in London?   \n",
       "15                            In what year did the London Underground begin?   \n",
       "16                   In what year was the London Underground Station closed?   \n",
       "17                                         What railway line opened in 1880?   \n",
       "18                            What railway line was built in London in 1880?   \n",
       "19                          What railway line was built in the 18th century?   \n",
       "\n",
       "                  answer  \n",
       "0                   1933  \n",
       "1                   1902  \n",
       "2                   1933  \n",
       "3   Metropolitan Railway  \n",
       "4                   1898  \n",
       "5                     80  \n",
       "6                   1933  \n",
       "7                   1933  \n",
       "8                     80  \n",
       "9                   1898  \n",
       "10  Metropolitan Railway  \n",
       "11  Metropolitan Railway  \n",
       "12                  1933  \n",
       "13          19th century  \n",
       "14              Bakerloo  \n",
       "15                  1933  \n",
       "16                  1933  \n",
       "17   The Piccadilly line  \n",
       "18  Metropolitan Railway  \n",
       "19  Metropolitan Railway  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_questions_with_confidence2(underground_context, underground_questions) # underground qs using distilbert approx 15 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.551449e-01</td>\n",
       "      <td>In what year did the London Underground begin?</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.581340e-01</td>\n",
       "      <td>In what year did the UERL begin to be built?</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.551449e-01</td>\n",
       "      <td>In what year did the London Underground begin?</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.702023e-07</td>\n",
       "      <td>What railway line was built in the 18th century?</td>\n",
       "      <td>Piccadilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.806922e-06</td>\n",
       "      <td>In what year did the Thames &amp; City Railway open?</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.153477e-01</td>\n",
       "      <td>How many kilometers long did it take to travel through London's Station?</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.953299e-01</td>\n",
       "      <td>When did the London Underground first operate?</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.517956e-01</td>\n",
       "      <td>In what year was the London Underground Station opened?</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.730436e-01</td>\n",
       "      <td>How many kilometers long was the London Underground Station?</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.806922e-06</td>\n",
       "      <td>In what year did the Thames &amp; City Railway open?</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.866657e-05</td>\n",
       "      <td>What railway line was built in London in the 18th century?</td>\n",
       "      <td>Bakerloo and Central London Railways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.025713e-01</td>\n",
       "      <td>What railway line was built in the London Underground?</td>\n",
       "      <td>Metropolitan Railway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.815155e-01</td>\n",
       "      <td>When did the UERL begin to run through the London Underground?</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.079213e-01</td>\n",
       "      <td>When did the London Underground begin?</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.118048e-01</td>\n",
       "      <td>What was the name of the first railway station in London?</td>\n",
       "      <td>Metropolitan Railway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.551449e-01</td>\n",
       "      <td>In what year did the London Underground begin?</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.844229e-04</td>\n",
       "      <td>In what year was the London Underground Station closed?</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.758247e-07</td>\n",
       "      <td>What railway line opened in 1880?</td>\n",
       "      <td>Bakerloo and Central London Railways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.754227e-04</td>\n",
       "      <td>What railway line was built in London in 1880?</td>\n",
       "      <td>Circle line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.702023e-07</td>\n",
       "      <td>What railway line was built in the 18th century?</td>\n",
       "      <td>Piccadilly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      confidence  \\\n",
       "0   2.551449e-01   \n",
       "1   9.581340e-01   \n",
       "2   2.551449e-01   \n",
       "3   4.702023e-07   \n",
       "4   2.806922e-06   \n",
       "5   1.153477e-01   \n",
       "6   2.953299e-01   \n",
       "7   2.517956e-01   \n",
       "8   5.730436e-01   \n",
       "9   2.806922e-06   \n",
       "10  1.866657e-05   \n",
       "11  5.025713e-01   \n",
       "12  7.815155e-01   \n",
       "13  5.079213e-01   \n",
       "14  3.118048e-01   \n",
       "15  2.551449e-01   \n",
       "16  1.844229e-04   \n",
       "17  9.758247e-07   \n",
       "18  1.754227e-04   \n",
       "19  4.702023e-07   \n",
       "\n",
       "                                                                    question  \\\n",
       "0                             In what year did the London Underground begin?   \n",
       "1                               In what year did the UERL begin to be built?   \n",
       "2                             In what year did the London Underground begin?   \n",
       "3                           What railway line was built in the 18th century?   \n",
       "4                           In what year did the Thames & City Railway open?   \n",
       "5   How many kilometers long did it take to travel through London's Station?   \n",
       "6                             When did the London Underground first operate?   \n",
       "7                    In what year was the London Underground Station opened?   \n",
       "8               How many kilometers long was the London Underground Station?   \n",
       "9                           In what year did the Thames & City Railway open?   \n",
       "10                What railway line was built in London in the 18th century?   \n",
       "11                    What railway line was built in the London Underground?   \n",
       "12            When did the UERL begin to run through the London Underground?   \n",
       "13                                    When did the London Underground begin?   \n",
       "14                 What was the name of the first railway station in London?   \n",
       "15                            In what year did the London Underground begin?   \n",
       "16                   In what year was the London Underground Station closed?   \n",
       "17                                         What railway line opened in 1880?   \n",
       "18                            What railway line was built in London in 1880?   \n",
       "19                          What railway line was built in the 18th century?   \n",
       "\n",
       "                                  answer  \n",
       "0                           19th century  \n",
       "1                                   1902  \n",
       "2                           19th century  \n",
       "3                             Piccadilly  \n",
       "4                                   1898  \n",
       "5                                     80  \n",
       "6                           19th century  \n",
       "7                                   1863  \n",
       "8                                     80  \n",
       "9                                   1898  \n",
       "10  Bakerloo and Central London Railways  \n",
       "11                  Metropolitan Railway  \n",
       "12                                  1902  \n",
       "13                          19th century  \n",
       "14                  Metropolitan Railway  \n",
       "15                          19th century  \n",
       "16                                  1915  \n",
       "17  Bakerloo and Central London Railways  \n",
       "18                           Circle line  \n",
       "19                            Piccadilly  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_questions_with_confidence(underground_context, underground_questions) #using roberta approx 35 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Cat questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A cat whose pictures went viral for regularly visiting a railway station is releasing a Christmas single. Four-year-old Nala has been delighting commuters who have been taking photos of her at Stevenage station. Owner Natasha Ambler revealed the cat was releasing a single called Meow and has been approached for a book deal. The ginger tabby has also recorded a video for the song due to be released this week, under the name Nala the Station Cat. It has been produced by Danny Kirsch, who wrote it with Joe Killington, while Nala is also co-credited as a songwriter, as well as a vocalist. Ms Ambler said \"we want to spread the happiness that Stevenage has had, and she\\'s had on socials to the world\". The single is officially released on Wednesday and BBC Three Counties Radio\\'s Justin Dealey gave the single an exclusive first play on Sunday. \"I\\'m slightly lost for words,\" said the presenter after the song finished. Nala\\'s owner replied: \"So am I to be fair.\" The musical cat does not yet have an agent and her owner said \"we\\'re all doing our emails ourselves; it\\'s quite new to us\". \"We\\'ll start small and hopefully she gets in the charts, but number one would be fantastic,\" she added. Charity campaigners LadBaby have filled the coveted Christmas number one single spot every year for the last five years. All proceeds from the single will be donated to the RSPCA and Stevenage homelessness charity Feed Up Warm Up. The music video, filmed at Stevenage railway station, will be unveiled before Christmas. Follow East of England news on Facebook, Instagram and X. Got a story? Email eastofenglandnews@bbc.co.uk or WhatsApp 0800 169 1830'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example questions - cat article\n",
    "bbc_cat_questions = ['Where will profit go?','Who produced the song?','What is the song called?',\\\n",
    "             'Who gave the song its first play?','When will the song be released?','Who wrote the song?',\\\n",
    "             'Where was the video filmed?','How has nala been delighting commuters?',\\\n",
    "             \"Who's pictures went viral?\", 'All proceeds from the single will be what?', 'What links Danny and Joe?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where will profit go?',\n",
       " 'Who produced the song?',\n",
       " 'What is the song called?',\n",
       " 'Who gave the song its first play?',\n",
       " 'When will the song be released?',\n",
       " 'Who wrote the song?',\n",
       " 'Where was the video filmed?',\n",
       " 'How has nala been delighting commuters?',\n",
       " \"Who's pictures went viral?\",\n",
       " 'All proceeds from the single will be what?',\n",
       " 'What links Danny and Joe?']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_cat_questions # 2 if passed by 2, 1 if passed by 1\n",
    "# RSPCA and Stevenage homelessness charity Feed Up Warm Up 2, 1\n",
    "# Danny Kirsch 2, 1\n",
    "# Meow 2, 1\n",
    "# Justin Dealey 2, 1\n",
    "# Stevenage railway station 2, 1\n",
    "# regularly visiting a railway station 2, 1\n",
    "# Nala 1\n",
    "# donated to the RSPCA and Stevenage homelessness charity Feed Up Warm Up 1\n",
    "# producer / writer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.535661</td>\n",
       "      <td>Where will profit go?</td>\n",
       "      <td>RSPCA and Stevenage homelessness charity Feed Up Warm Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.981917</td>\n",
       "      <td>Who produced the song?</td>\n",
       "      <td>Danny Kirsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.883597</td>\n",
       "      <td>What is the song called?</td>\n",
       "      <td>Meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.992343</td>\n",
       "      <td>Who gave the song its first play?</td>\n",
       "      <td>Justin Dealey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.852285</td>\n",
       "      <td>When will the song be released?</td>\n",
       "      <td>before Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.482969</td>\n",
       "      <td>Who wrote the song?</td>\n",
       "      <td>Danny Kirsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.920912</td>\n",
       "      <td>Where was the video filmed?</td>\n",
       "      <td>Stevenage railway station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.444611</td>\n",
       "      <td>How has nala been delighting commuters?</td>\n",
       "      <td>taking photos of her at Stevenage station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.617798</td>\n",
       "      <td>Who's pictures went viral?</td>\n",
       "      <td>A cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.024473</td>\n",
       "      <td>All proceeds from the single will be what?</td>\n",
       "      <td>Feed Up Warm Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.124450</td>\n",
       "      <td>What links Danny and Joe?</td>\n",
       "      <td>Facebook, Instagram and X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    confidence                                    question  \\\n",
       "0     0.535661                       Where will profit go?   \n",
       "1     0.981917                      Who produced the song?   \n",
       "2     0.883597                    What is the song called?   \n",
       "3     0.992343           Who gave the song its first play?   \n",
       "4     0.852285             When will the song be released?   \n",
       "5     0.482969                         Who wrote the song?   \n",
       "6     0.920912                 Where was the video filmed?   \n",
       "7     0.444611     How has nala been delighting commuters?   \n",
       "8     0.617798                  Who's pictures went viral?   \n",
       "9     0.024473  All proceeds from the single will be what?   \n",
       "10    0.124450                   What links Danny and Joe?   \n",
       "\n",
       "                                                      answer  \n",
       "0   RSPCA and Stevenage homelessness charity Feed Up Warm Up  \n",
       "1                                               Danny Kirsch  \n",
       "2                                                       Meow  \n",
       "3                                              Justin Dealey  \n",
       "4                                           before Christmas  \n",
       "5                                               Danny Kirsch  \n",
       "6                                  Stevenage railway station  \n",
       "7                  taking photos of her at Stevenage station  \n",
       "8                                                      A cat  \n",
       "9                                            Feed Up Warm Up  \n",
       "10                                 Facebook, Instagram and X  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_questions_with_confidence2(bbc_article_text, bbc_cat_questions) # 12 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101562</td>\n",
       "      <td>Where will profit go?</td>\n",
       "      <td>RSPCA and Stevenage homelessness charity Feed Up Warm Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963533</td>\n",
       "      <td>Who produced the song?</td>\n",
       "      <td>Danny Kirsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.819190</td>\n",
       "      <td>What is the song called?</td>\n",
       "      <td>Meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781142</td>\n",
       "      <td>Who gave the song its first play?</td>\n",
       "      <td>Justin Dealey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.682033</td>\n",
       "      <td>When will the song be released?</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.440879</td>\n",
       "      <td>Who wrote the song?</td>\n",
       "      <td>Danny Kirsch, who wrote it with Joe Killington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.842697</td>\n",
       "      <td>Where was the video filmed?</td>\n",
       "      <td>Stevenage railway station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.508643</td>\n",
       "      <td>How has nala been delighting commuters?</td>\n",
       "      <td>taking photos of her at Stevenage station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.308242</td>\n",
       "      <td>Who's pictures went viral?</td>\n",
       "      <td>Nala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.237600</td>\n",
       "      <td>All proceeds from the single will be what?</td>\n",
       "      <td>donated to the RSPCA and Stevenage homelessness charity Feed Up Warm Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.032588</td>\n",
       "      <td>What links Danny and Joe?</td>\n",
       "      <td>wrote it with Joe Killington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    confidence                                    question  \\\n",
       "0     0.101562                       Where will profit go?   \n",
       "1     0.963533                      Who produced the song?   \n",
       "2     0.819190                    What is the song called?   \n",
       "3     0.781142           Who gave the song its first play?   \n",
       "4     0.682033             When will the song be released?   \n",
       "5     0.440879                         Who wrote the song?   \n",
       "6     0.842697                 Where was the video filmed?   \n",
       "7     0.508643     How has nala been delighting commuters?   \n",
       "8     0.308242                  Who's pictures went viral?   \n",
       "9     0.237600  All proceeds from the single will be what?   \n",
       "10    0.032588                   What links Danny and Joe?   \n",
       "\n",
       "                                                                     answer  \n",
       "0                  RSPCA and Stevenage homelessness charity Feed Up Warm Up  \n",
       "1                                                              Danny Kirsch  \n",
       "2                                                                      Meow  \n",
       "3                                                             Justin Dealey  \n",
       "4                                                                 Wednesday  \n",
       "5                            Danny Kirsch, who wrote it with Joe Killington  \n",
       "6                                                 Stevenage railway station  \n",
       "7                                 taking photos of her at Stevenage station  \n",
       "8                                                                      Nala  \n",
       "9   donated to the RSPCA and Stevenage homelessness charity Feed Up Warm Up  \n",
       "10                                             wrote it with Joe Killington  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_questions_with_confidence(bbc_article_text, bbc_cat_questions) # 13 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Chimp questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimp_questions = ['What is a typical group size in the wild?', 'Who is the son of Ai?', 'What can Ai do with the keyboard?',\\\n",
    "                   'What was Ai the first chimpanzee to do?']\n",
    "chimp_answers = ['20', # 2\n",
    "                 'Ayumu', # 2\n",
    "                 'interact with a computer', \n",
    "                 'use arabic numerals to represent numbers'] # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.491928</td>\n",
       "      <td>What is a typical group size in the wild?</td>\n",
       "      <td>20 chimpanzees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.982641</td>\n",
       "      <td>Who is the son of Ai?</td>\n",
       "      <td>Ayumu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.654109</td>\n",
       "      <td>What can Ai do with the keyboard?</td>\n",
       "      <td>paint and draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.643580</td>\n",
       "      <td>What was Ai the first chimpanzee to do?</td>\n",
       "      <td>learned to use Arabic numerals to represent numbers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confidence                                   question  \\\n",
       "0    0.491928  What is a typical group size in the wild?   \n",
       "1    0.982641                      Who is the son of Ai?   \n",
       "2    0.654109          What can Ai do with the keyboard?   \n",
       "3    0.643580    What was Ai the first chimpanzee to do?   \n",
       "\n",
       "                                                answer  \n",
       "0                                       20 chimpanzees  \n",
       "1                                                Ayumu  \n",
       "2                                       paint and draw  \n",
       "3  learned to use Arabic numerals to represent numbers  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_questions_with_confidence2(wikipedia_article_text, chimp_questions) # 13 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.491928</td>\n",
       "      <td>What is a typical group size in the wild?</td>\n",
       "      <td>20 chimpanzees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.982641</td>\n",
       "      <td>Who is the son of Ai?</td>\n",
       "      <td>Ayumu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.654109</td>\n",
       "      <td>What can Ai do with the keyboard?</td>\n",
       "      <td>paint and draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.643580</td>\n",
       "      <td>What was Ai the first chimpanzee to do?</td>\n",
       "      <td>learned to use Arabic numerals to represent numbers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confidence                                   question  \\\n",
       "0    0.491928  What is a typical group size in the wild?   \n",
       "1    0.982641                      Who is the son of Ai?   \n",
       "2    0.654109          What can Ai do with the keyboard?   \n",
       "3    0.643580    What was Ai the first chimpanzee to do?   \n",
       "\n",
       "                                                answer  \n",
       "0                                       20 chimpanzees  \n",
       "1                                                Ayumu  \n",
       "2                                       paint and draw  \n",
       "3  learned to use Arabic numerals to represent numbers  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_questions_with_confidence2(wikipedia_article_text, chimp_questions) # 15 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Example images for processing\"\"\"\n",
    "\"\"\"Text\"\"\"\n",
    "# Invoice\n",
    "invoice = 'https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png'\n",
    "# Simple poster\n",
    "simple = 'https://www.11thhourracingteam.org/wp-content/uploads/11th-hour-racing-team-how-to-create-a-sustainability-policy-horizontal-3-1-1536x1056.png'\n",
    "# Complex poster\n",
    "complicated = 'https://cdn.greenmatch.co.uk/cdn-cgi/image/format=auto/2/2023/07/MAY23_4_02-Plastic-Waste_Global-Waste_2-1-663x1024.png'\n",
    "# Microscopes text book page via web link\n",
    "microscope = 'https://m.media-amazon.com/images/I/71Ts-QXYIhL._SL1500_.jpg'\n",
    "# Magnification text book page downloaded to absolute file path\n",
    "magnification = '/home/george/Downloads/magnification.jpg'\n",
    "\n",
    "\"\"\"Handwriting\"\"\"\n",
    "# Nice clear handwriting and cursive handwriting\n",
    "clear = 'https://steemitimages.com/DQmcdbSGrnA9zeqWrYHD8EkNjvF9uxQCAeB7qnucUShpNDe/IMG_7345.PNG'\n",
    "# Tricky handwriting\n",
    "tricky = 'https://www.researchgate.net/profile/Neeta-Nain/publication/299666231/figure/fig1/AS:491693964304386@1494240384780/Example-image-of-a-general-handwritten-text-paragraph-from-IAM-dataset-4.png'\n",
    "y5 = 'https://thelinksprimary.org.uk/wp-content/uploads/2023/10/Handwriting-Y6.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Other ideas to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"These are possible ways to better process images\"\"\"\n",
    "\"\"\"visual bert needs more configuring\"\"\"\n",
    "https://huggingface.co/daki97/visualbert_finetuned_easy_vqa\n",
    "https://huggingface.co/docs/transformers/model_doc/visual_bert#overview # overview is part of the url, not a comment\n",
    "https://github.com/huggingface/transformers/blob/main/examples/research_projects/visual_bert/demo.ipynb\n",
    "\"\"\"layout needs more configuring\"\"\"\n",
    "https://huggingface.co/docs/transformers/model_doc/layoutlmv3\n",
    "\"\"\"should work for extracting printed text, but only works for single lines\"\"\"\n",
    "https://huggingface.co/microsoft/trocr-base-printed\n",
    "\"\"\"suggestions on how to split into multiple lines for extracted text and handwriting\"\"\"\n",
    "https://github.com/microsoft/unilm/issues/628\n",
    "https://discuss.huggingface.co/t/trocr-fine-tuning/13293/3\n",
    "\"\"\"vision encoder requires more configuration\"\"\"\n",
    "https://huggingface.co/docs/transformers/model_doc/vision-encoder-decoder\n",
    "\"\"\"Generate LaTEX from images\"\"\"\n",
    "https://huggingface.co/Norm/nougat-latex-base\n",
    "\"\"\"Automate snipping\"\"\"\n",
    "https://support.techsmith.com/hc/en-us/articles/115002022732?ipc_item_name=snagit&ipc_platform=windows&utm_campaign=sw23&utm_medium=snagit&utm_source=product\n",
    "https://www.movavi.com/learning-portal/snipping-tool-for-linux.html\n",
    "https://screencloud.net/\n",
    "https://www.codeproject.com/Articles/485883/Create-your-own-Snipping-Tool\n",
    "https://www.codeinwp.com/blog/best-website-screenshot-tools/#gref\n",
    "# Note it may not be possible to snip elements outside the browser from within the browser, for security reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exploration of retraining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da91f8a9279849ffb4b269e6c860b796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:37:16.271633: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-12-01 16:37:16.292324: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-12-01 16:37:16.292539: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (george-ThinkPad-X220-Tablet): /proc/driver/nvidia/version does not exist\n",
      "2023-12-01 16:37:17.115447: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "2023-12-01 16:37:17.564863: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "2023-12-01 16:37:17.660538: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "2023-12-01 16:37:20.262567: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['qa_outputs.bias', 'roberta.embeddings.position_ids', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "question_answerer_train = TFAutoModelForSequenceClassification.from_pretrained('deepset/roberta-base-squad2', from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answerer_train."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
