{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answering questions using Roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main solution using pre-made model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/george/Documents/LeWagon/Transformers_Hugging_Face\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Install requirements\"\"\"\n",
    "# Install the transformers library from HuggingFace\n",
    "!pip install transformers torch pytesseract\n",
    "# You'll also need some extra tools that some of these models use under the hood\n",
    "! pip install sentencepiece sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 10:33:38.059974: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-12-01 10:33:38.060008: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-12-01 10:33:38.097288: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-01 10:33:39.078537: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-01 10:33:39.078708: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-01 10:33:39.078726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Import packages\"\"\"\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"Import our question answering model\"\"\"\n",
    "question_answerer = pipeline(model = 'deepset/roberta-base-squad2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.688135</td>\n",
       "      <td>Where is Spain?</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confidence         question  answer\n",
       "0    0.688135  Where is Spain?  Europe"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_questions_with_confidence(content, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is just some text to use as an example.\n",
      "It does not particularly say much that is very interesting or useful.\n",
      "The purpose of the article is that I can confirm how to open and read articles and to see whether my model can answer questions based on it.\n",
      "Animals: mouse, cat, horse, hippo, elephant, whale.\n",
      "Spain is a country in Europe.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Open a file as a possible source of context\"\"\"\n",
    "file = open(\"/home/george/Documents/example_article.txt\", \"r\") # Example file\n",
    "content = file.read()\n",
    "print(content)\n",
    "file.close()\n",
    "\n",
    "question = ['Where is Spain?'] # Example question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/george/Documents/LeWagon/Transformers_Hugging_Face/quizachu/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_questions_with_confidence(context = \"You did not specify any content\", questions = [\"Did you mean to specify a question?\"]):\n",
    "    \"\"\"Takes a list called 'questions' that contains the questions to answer\n",
    "    Takes some text called 'content' as a source for answering questions\n",
    "    Returns a dataframe of the questions with their answers and an assessment of confidence in the answers\n",
    "    If no context or content is provided, returns a dataframe requesting these\"\"\"\n",
    "    \n",
    "    # List to fill with questions, answers, and confidence\n",
    "    questions_answers = []\n",
    "    \n",
    "    # For each question create an empty dictionary and call the question_answerer model on the question\n",
    "    for q in questions: \n",
    "        q_a_dict = {}\n",
    "        q_a = question_answerer(question=q, context=context)\n",
    "        \n",
    "        # Assign the question, and outputs of the question_answerer model to the dictionary\n",
    "        q_a_dict['confidence'] = q_a['score']\n",
    "        q_a_dict['question'] = q\n",
    "        q_a_dict['answer'] = q_a['answer'].replace('\\n', ' ')\n",
    "        \n",
    "        # Add the dictionary to the list and then convert the final list of dicts to a dataframe\n",
    "        questions_answers.append(q_a_dict) \n",
    "    questions_answers = pd.DataFrame(questions_answers)\n",
    "    \n",
    "    # Set a large maxcolwidth to allow for potentially long answers\n",
    "    pd.options.display.max_colwidth = 20000\n",
    "    \n",
    "    return questions_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are your 4 questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_question_number</th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.963533</td>\n",
       "      <td>Who produced the song?</td>\n",
       "      <td>Danny Kirsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>Where was the video filmed?</td>\n",
       "      <td>Stevenage railway station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.819190</td>\n",
       "      <td>What is the song called?</td>\n",
       "      <td>Meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.781142</td>\n",
       "      <td>Who gave the song its first play?</td>\n",
       "      <td>Justin Dealey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_question_number  confidence                           question  \\\n",
       "0                         1    0.963533             Who produced the song?   \n",
       "1                         6    0.842697        Where was the video filmed?   \n",
       "2                         2    0.819190           What is the song called?   \n",
       "3                         3    0.781142  Who gave the song its first play?   \n",
       "\n",
       "                      answer  \n",
       "0               Danny Kirsch  \n",
       "1  Stevenage railway station  \n",
       "2                       Meow  \n",
       "3              Justin Dealey  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_top_n_questions(bbc_article_text, bbc_cat_questions, 0.6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_n_questions(context, questions, c = 0.5, n = 5):\n",
    "    \"\"\"Selects the top n questions with the highest confidence level c\n",
    "    User can define how many questions are required and the minimum confidence level\"\"\"\n",
    "    \n",
    "    # Call answer_questions to get a df of questions and answers\n",
    "    questions_answers = answer_questions_with_confidence(context, questions)\n",
    "    \n",
    "    # Filter for confidence\n",
    "    conf_questions = questions_answers[questions_answers['confidence'] > c] \n",
    "    \n",
    "    # Return n questions ordered by confidence\n",
    "    selected_questions = conf_questions.sort_values(by='confidence', ascending=False).head(n)\\\n",
    "    .reset_index().rename(columns={'index':'original_question_number'}) \n",
    "    \n",
    "    \"\"\"Check whether enough questions can be returned and explain why if not\"\"\"\n",
    "    \n",
    "    # Were enough questions generated?\n",
    "    if len(questions_answers) < n:\n",
    "        print(f\"Only {len(questions_answers)} questions were generated\")\n",
    "        \n",
    "        # Did enough questions meet the confidence requirement?\n",
    "        if len(selected_questions) == 0:\n",
    "            print(\"No questions met your required confidence level.\")\n",
    "        elif len(selected_questions) < n: \n",
    "            print(f\"Not enough questions met your required confidence level,\\\n",
    " but here {'is' if len(selected_questions) == 1 else 'are'} the {len(selected_questions)} that did:\")\n",
    "        else:\n",
    "            print(f\"Here are your {n} questions\")\n",
    "            \n",
    "    else:\n",
    "        # Did enough questions meet the confidence requirement?\n",
    "        if len(selected_questions) == 0:\n",
    "            print(\"No questions met your required confidence level.\")\n",
    "        elif len(selected_questions) < n: \n",
    "            print(f\"Not enough questions met your required confidence level,\\\n",
    " but here {'is' if len(selected_questions) == 1 else 'are'} the {len(selected_questions)} that did:\")\n",
    "        else:\n",
    "            print(f\"Here are your {n} questions\")\n",
    "            \n",
    "    return selected_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.439633</td>\n",
       "      <td>When were the first microscopes developed?</td>\n",
       "      <td>mid-17th century</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confidence                                    question            answer\n",
       "0    0.439633  When were the first microscopes developed?  mid-17th century"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_questions_with_confidence(result_text, ['When were the first microscopes developed?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101562</td>\n",
       "      <td>Where will profit go?</td>\n",
       "      <td>RSPCA and Stevenage homelessness charity Feed Up Warm Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963533</td>\n",
       "      <td>Who produced the song?</td>\n",
       "      <td>Danny Kirsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.819190</td>\n",
       "      <td>What is the song called?</td>\n",
       "      <td>Meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781142</td>\n",
       "      <td>Who gave the song its first play?</td>\n",
       "      <td>Justin Dealey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.682033</td>\n",
       "      <td>When will the song be released?</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.440879</td>\n",
       "      <td>Who wrote the song?</td>\n",
       "      <td>Danny Kirsch, who wrote it with Joe Killington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.842697</td>\n",
       "      <td>Where was the video filmed?</td>\n",
       "      <td>Stevenage railway station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.508643</td>\n",
       "      <td>How has nala been delighting commuters?</td>\n",
       "      <td>taking photos of her at Stevenage station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.308242</td>\n",
       "      <td>Who's pictures went viral?</td>\n",
       "      <td>Nala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.237600</td>\n",
       "      <td>All proceeds from the single will be what?</td>\n",
       "      <td>donated to the RSPCA and Stevenage homelessness charity Feed Up Warm Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.032588</td>\n",
       "      <td>What links Danny and Joe?</td>\n",
       "      <td>wrote it with Joe Killington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    confidence                                    question  \\\n",
       "0     0.101562                       Where will profit go?   \n",
       "1     0.963533                      Who produced the song?   \n",
       "2     0.819190                    What is the song called?   \n",
       "3     0.781142           Who gave the song its first play?   \n",
       "4     0.682033             When will the song be released?   \n",
       "5     0.440879                         Who wrote the song?   \n",
       "6     0.842697                 Where was the video filmed?   \n",
       "7     0.508643     How has nala been delighting commuters?   \n",
       "8     0.308242                  Who's pictures went viral?   \n",
       "9     0.237600  All proceeds from the single will be what?   \n",
       "10    0.032588                   What links Danny and Joe?   \n",
       "\n",
       "                                                                     answer  \n",
       "0                  RSPCA and Stevenage homelessness charity Feed Up Warm Up  \n",
       "1                                                              Danny Kirsch  \n",
       "2                                                                      Meow  \n",
       "3                                                             Justin Dealey  \n",
       "4                                                                 Wednesday  \n",
       "5                            Danny Kirsch, who wrote it with Joe Killington  \n",
       "6                                                 Stevenage railway station  \n",
       "7                                 taking photos of her at Stevenage station  \n",
       "8                                                                      Nala  \n",
       "9   donated to the RSPCA and Stevenage homelessness charity Feed Up Warm Up  \n",
       "10                                             wrote it with Joe Killington  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_questions_with_confidence(bbc_article_text, bbc_cat_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Not enough questions met your required confidence level, but here are the 12 that did:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_question_number</th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.958134</td>\n",
       "      <td>In what year did the UERL begin to be built?</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>0.781515</td>\n",
       "      <td>When did the UERL begin to run through the London Underground?</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.573044</td>\n",
       "      <td>How many kilometers long was the London Underground Station?</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0.507921</td>\n",
       "      <td>When did the London Underground begin?</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.502571</td>\n",
       "      <td>What railway line was built in the London Underground?</td>\n",
       "      <td>Metropolitan Railway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>What was the name of the first railway station in London?</td>\n",
       "      <td>Metropolitan Railway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.295330</td>\n",
       "      <td>When did the London Underground first operate?</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.255145</td>\n",
       "      <td>In what year did the London Underground begin?</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.255145</td>\n",
       "      <td>In what year did the London Underground begin?</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>0.255145</td>\n",
       "      <td>In what year did the London Underground begin?</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>0.251796</td>\n",
       "      <td>In what year was the London Underground Station opened?</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.115348</td>\n",
       "      <td>How many kilometers long did it take to travel through London's Station?</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    original_question_number  confidence  \\\n",
       "0                          1    0.958134   \n",
       "1                         12    0.781515   \n",
       "2                          8    0.573044   \n",
       "3                         13    0.507921   \n",
       "4                         11    0.502571   \n",
       "5                         14    0.311805   \n",
       "6                          6    0.295330   \n",
       "7                          0    0.255145   \n",
       "8                          2    0.255145   \n",
       "9                         15    0.255145   \n",
       "10                         7    0.251796   \n",
       "11                         5    0.115348   \n",
       "\n",
       "                                                                    question  \\\n",
       "0                               In what year did the UERL begin to be built?   \n",
       "1             When did the UERL begin to run through the London Underground?   \n",
       "2               How many kilometers long was the London Underground Station?   \n",
       "3                                     When did the London Underground begin?   \n",
       "4                     What railway line was built in the London Underground?   \n",
       "5                  What was the name of the first railway station in London?   \n",
       "6                             When did the London Underground first operate?   \n",
       "7                             In what year did the London Underground begin?   \n",
       "8                             In what year did the London Underground begin?   \n",
       "9                             In what year did the London Underground begin?   \n",
       "10                   In what year was the London Underground Station opened?   \n",
       "11  How many kilometers long did it take to travel through London's Station?   \n",
       "\n",
       "                  answer  \n",
       "0                   1902  \n",
       "1                   1902  \n",
       "2                     80  \n",
       "3           19th century  \n",
       "4   Metropolitan Railway  \n",
       "5   Metropolitan Railway  \n",
       "6           19th century  \n",
       "7           19th century  \n",
       "8           19th century  \n",
       "9           19th century  \n",
       "10                  1863  \n",
       "11                    80  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_top_n_questions(underground_context, underground_questions, c = 0.1, n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "underground_context = \"\"\"The history of the London Underground began in the 19th century with the construction of the Metropolitan Railway, the world's first underground railway. The Metropolitan Railway, which opened in 1863 using gas-lit wooden carriages hauled by steam locomotives, worked with the District Railway to complete London's Circle line in 1884. Both railways expanded, the Metropolitan eventually extending as far as Verney Junction in Buckinghamshire, more than 50 miles (80 km) from Baker Street and the centre of London. The first deep-level tube line, the City and South London Railway, opened in 1890 with electric trains. This was followed by the Waterloo & City Railway in 1898, the Central London Railway in 1900, and the Great Northern and City Railway in 1904. The Underground Electric Railways Company of London (UERL) was established in 1902 to fund the electrification of the District Railway and to complete and operate three tube lines, the Baker Street and Waterloo Railway, the Charing Cross, Euston and Hampstead Railway and the Great Northern, Piccadilly and Brompton Railway, which opened in 1906–07. By 1907 the District and Metropolitan Railways had electrified the underground sections of their lines.\n",
    "\n",
    "Under a joint marketing agreement between most of the companies in the early years of the 20th century, UNDERGROUND signs appeared outside stations in central London. World War I delayed extensions of the Bakerloo and Central London Railways, and people used the tube stations as shelters during Zeppelin air raids by June 1915. After the war, government-backed financial guarantees were used to expand the network, and the tunnels of the City and South London and Charing Cross, Euston and Hampstead Railways were linked at Euston and Kennington, although the combined service was not named the Northern line until later. The Piccadilly line was extended north to Cockfosters and took over District line branches to Harrow (later Uxbridge) and Hounslow. In 1933, the underground railways and all London area tram and bus operators were merged into the London Passenger Transport Board (LPTB). The outlying branches of the Metropolitan were closed; various upgrades were planned. The Bakerloo line's extension to take over the Metropolitan's Stanmore branch, and extensions of the Central and Northern lines, formed part of the 1930s New Works Programme. The outbreak of World War II in 1939 halted or interrupted some of this work, and many tube stations were used as air-raid shelters. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "underground_questions = [\"In what year did the London Underground begin?\",\n",
    "\"In what year did the UERL begin to be built?\",\n",
    "\"In what year did the London Underground begin?\",\n",
    "\"What railway line was built in the 18th century?\",\n",
    "\"In what year did the Thames & City Railway open?\",\n",
    "\"How many kilometers long did it take to travel through London's Station?\",\n",
    "\"When did the London Underground first operate?\",\n",
    "\"In what year was the London Underground Station opened?\",\n",
    "\"How many kilometers long was the London Underground Station?\",\n",
    "\"In what year did the Thames & City Railway open?\",\n",
    "\"What railway line was built in London in the 18th century?\",\n",
    "\"What railway line was built in the London Underground?\",\n",
    "\"When did the UERL begin to run through the London Underground?\",\n",
    "\"When did the London Underground begin?\",\n",
    "\"What was the name of the first railway station in London?\",\n",
    "\"In what year did the London Underground begin?\",\n",
    "\"In what year was the London Underground Station closed?\",\n",
    "\"What railway line opened in 1880?\",\n",
    "\"What railway line was built in London in 1880?\",\n",
    "\"What railway line was built in the 18th century?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Importing audio as input for questions or answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Installs to analyse audio\"\"\"\n",
    "!sudo apt install ffmpeg\n",
    "!pip3 install datasets\n",
    "!pip install SoundFile\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Example audio to analyse\"\"\"\n",
    "!mkdir data\n",
    "!curl https://wagon-public-datasets.s3.amazonaws.com/deep_learning_datasets/harvard.wav > data/harvard.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Packages for audio\"\"\"\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Read the audio file and play it to verify\"\"\"\n",
    "rate, audio = wavfile.read(\"data/harvard.wav\")\n",
    "Audio(audio.T, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Transcription of a downloaded wav file\"\"\"\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import librosa  \n",
    "\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "model.config.forced_decoder_ids = None\n",
    "\n",
    "# Whisper requires a sampling rate of 16000 so must convert this with librosa\n",
    "audio, rate = librosa.load('data/harvard.wav', sr=16000)\n",
    "input_features = processor(audio, sampling_rate=rate, return_tensors=\"pt\").input_features \n",
    "\n",
    "# generate token ids\n",
    "predicted_ids = model.generate(input_features)\n",
    "# decode token ids to text\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)\n",
    "\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Transcription of a flac file from hugging face\"\"\"\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "model.config.forced_decoder_ids = None\n",
    "\n",
    "# load dummy dataset and read audio files\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "sample = ds[0][\"audio\"]\n",
    "input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features \n",
    "\n",
    "# generate token ids\n",
    "predicted_ids = model.generate(input_features)\n",
    "# decode token ids to text\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)\n",
    "\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Processing visual input for questions or answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final OCR extraction code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For \"\"\"\n",
    "!sudo apt install tesseract-ocr  \n",
    "!sudo apt install libtesseract-dev\n",
    "!pip install Pillow pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Result:\n",
      "B 1 Cell structure and\n",
      "\n",
      "transport\n",
      "\n",
      " \n",
      "\n",
      "1.1 The world of the microscope\n",
      "\n",
      "Learning objectives\n",
      "\n",
      "After this topic, you should know:\n",
      "\n",
      "e@ how microscopy techniques have\n",
      "developed over time\n",
      "\n",
      "@ the differences in magnification and\n",
      "resolution between a light microscope\n",
      "and an electron microscope\n",
      "\n",
      "@ how to calculate the magnification,\n",
      "teal size, and image size of a specimen.\n",
      "\n",
      "Ge wvrriewe\n",
      "\n",
      "    \n",
      "\n",
      "coarse focus ‘a lens\n",
      "\n",
      "stage\n",
      "fine focus,\n",
      "\n",
      "slide\n",
      "\n",
      "light\n",
      "\n",
      "Figure 1 A light microscope\n",
      "\n",
      "Living things are all made up of cells, but most cells are so small you can\n",
      "only see them using a microscope. It is important to grasp the units used for\n",
      "such tiny specimens before you start to look at them.\n",
      "\n",
      "Using units\n",
      "1 kilometre (km) = 1000 metres (m)\n",
      "\n",
      "1m = 100centimetres (cm)\n",
      "1cm= 10 millimetres (mm)\n",
      "1mm = 1000 micrometres (um)\n",
      "\n",
      "1 um = 1000 nanometres (nm) — so a nanometre is 0.000000 001\n",
      "metres (or written in standard form as 1 x 10°°m).\n",
      "\n",
      " \n",
      "\n",
      "The first light microscopes were developed in the mid-17th century. Their\n",
      "development has continued ever since and they are still widely used to\n",
      "look at cells. Light microscopes use a beam of light to form an image of\n",
      "an object and the best can magnify around 2000 times («2000), although\n",
      "school microscopes usually only magnify several hundred times. They\n",
      "\n",
      "are relatively cheap, can be used almost anywhere, and can magnify live\n",
      "specimens (Figures 1 and 2).\n",
      "\n",
      "The invention of the electron microscope in the 1930s allowed biologists\n",
      "to see and understand more about the subcellular structures inside cells.\n",
      "These instruments use a beam of electrons to form an image and can\n",
      "magnify objects up to around 2000000 times. Transmission electron\n",
      "microscopes give 2D images with very high magnification and resolution.\n",
      "Scanning electron microscopes give dramatic 3D images but lower\n",
      "magnifications (Figure 3). Electron microscopes are large, very expensive,\n",
      "and have to be kept in special temperature, pressure, and humidity-\n",
      "controlled rooms.\n",
      "\n",
      "Calculating magnification\n",
      "\n",
      "You can calculate the magnification you are using with a light microscope\n",
      "very simply. You multiply the magnification of the eyepiece lens by the\n",
      "magnification of the objective lens. So if your eyepiece lens is x4 and your\n",
      "objective lens is x10, your overall magnification is:\n",
      "\n",
      "4x10=x40\n",
      "\n",
      "When you label drawings made using a microscope, make it clear that\n",
      "the magnification you give is the magnification at which you looked at\n",
      "the specimen (eg,, as viewed at x40).\n",
      "\n",
      "I\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This is not answering questions. It simply performs OCR on images.\n",
    "This would enable output from images to be put into the question answerer\n",
    "This should work with images obtained from the snipping tool.\n",
    "It does not recognise handwriting.\"\"\"\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def ocr_document(image_path):\n",
    "    # Open the image using the Pillow library\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Perform OCR using Tesseract\n",
    "    text = pytesseract.image_to_string(image)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "image_path = '/home/george/Downloads/microscope.jpg'\n",
    "result_text = ocr_document(image_path)\n",
    "\n",
    "print(\"OCR Result:\")\n",
    "print(result_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032588</td>\n",
       "      <td>What links Danny and Joe?</td>\n",
       "      <td>wrote it with Joe Killington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confidence                   question                        answer\n",
       "0    0.032588  What links Danny and Joe?  wrote it with Joe Killington"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_questions_with_confidence(bbc_article_text, ['What links Danny and Joe?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.253979</td>\n",
       "      <td>What does this tool capture?</td>\n",
       "      <td>a screenshot of anything on your desktop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confidence                      question  \\\n",
       "0    0.253979  What does this tool capture?   \n",
       "\n",
       "                                     answer  \n",
       "0  a screenshot of anything on your desktop  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Here we use the question answering model to answer questions about the OCR text\"\"\"\n",
    "answer_questions_with_confidence(result_text, ['What does this tool capture?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are previous attempts at various image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Example images for processing\"\"\"\n",
    "\"\"\"Text\"\"\"\n",
    "# Invoice\n",
    "invoice = 'https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png'\n",
    "# Simple poster\n",
    "simple = 'https://www.11thhourracingteam.org/wp-content/uploads/11th-hour-racing-team-how-to-create-a-sustainability-policy-horizontal-3-1-1536x1056.png'\n",
    "# Complex poster\n",
    "complicated = 'https://cdn.greenmatch.co.uk/cdn-cgi/image/format=auto/2/2023/07/MAY23_4_02-Plastic-Waste_Global-Waste_2-1-663x1024.png'\n",
    "# Microscopes text book page via web link\n",
    "microscope = 'https://m.media-amazon.com/images/I/71Ts-QXYIhL._SL1500_.jpg'\n",
    "# Magnification text book page downloaded to absolute file path\n",
    "magnification = '/home/george/Downloads/magnification.jpg'\n",
    "\n",
    "\"\"\"Handwriting\"\"\"\n",
    "# Nice clear handwriting and cursive handwriting\n",
    "clear = 'https://steemitimages.com/DQmcdbSGrnA9zeqWrYHD8EkNjvF9uxQCAeB7qnucUShpNDe/IMG_7345.PNG'\n",
    "# Tricky handwriting\n",
    "tricky = 'https://www.researchgate.net/profile/Neeta-Nain/publication/299666231/figure/fig1/AS:491693964304386@1494240384780/Example-image-of-a-general-handwritten-text-paragraph-from-IAM-dataset-4.png'\n",
    "y5 = 'https://thelinksprimary.org.uk/wp-content/uploads/2023/10/Handwriting-Y6.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### This is for reading images with text in, eg invoices or posters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at impira/layoutlm-invoices were not used when initializing LayoutLMForQuestionAnswering: ['token_classifier_head.weight', 'token_classifier_head.bias']\n",
      "- This IS expected if you are initializing LayoutLMForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\"\"\"First model - this answers questions about documents\n",
    "- this works for very simple documents \n",
    "but struggles for anything which implies relationships (e.g. two text boxes that relate to one another)\"\"\"\n",
    "ocr = pipeline(model = 'impira/layoutlm-invoices') #This struggles to find relationships between objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.7278719544410706,\n",
       "  'answer': 'Calculating the size of an object',\n",
       "  'start': 0,\n",
       "  'end': 5}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Question-answer format\"\"\"\n",
    "ocr(image='/home/george/Downloads/magnification.jpg',question=\"What does this page say?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is for reading handwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This works well for single lines of handwriting but does not support multiple lines.\n",
    "I need to split multiple line files into single lines.\"\"\"\n",
    "\n",
    "hw = pipeline(model = 'microsoft/trocr-base-handwritten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved line 1 to /home/george/Downloads/split_text/line_1.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This attempts to split images. It is the first time I gave up and got chatgpt to write code for me.\n",
    "It does not work very well - it identifies words but does not link them correctly as lines.\"\"\"\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pytesseract\n",
    "\n",
    "def split_and_save_handwritten_lines(image_path, output_directory):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use adaptive thresholding to preprocess the image\n",
    "    _, binary_image = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # List to store individual line images\n",
    "    line_images = []\n",
    "\n",
    "    # Minimum width and height threshold for a contour to be considered a line\n",
    "    min_width_threshold = 300\n",
    "    min_height_threshold = 20\n",
    "\n",
    "    # Iterate through contours\n",
    "    for i, contour in enumerate(contours):\n",
    "        # Get bounding box for each contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Filter out contours based on width and height\n",
    "        if w > min_width_threshold and h > min_height_threshold:\n",
    "            # Crop the original image to extract the line\n",
    "            line_image = image[y:y+h, x:x+w]\n",
    "\n",
    "            # Save the line image to the output directory\n",
    "            output_path = os.path.join(output_directory, f'line_{i+1}.png')\n",
    "            cv2.imwrite(output_path, line_image)\n",
    "\n",
    "            # Append the line image to the list\n",
    "            line_images.append(line_image)\n",
    "\n",
    "    return line_images\n",
    "\n",
    "# Example usage\n",
    "image_path = '/home/george/Downloads/Handwriting-Y4.png'\n",
    "output_directory = '/home/george/Downloads/split_text'\n",
    "lines = split_and_save_handwritten_lines(image_path, output_directory)\n",
    "\n",
    "# Print the paths of saved line images\n",
    "for i, line_image in enumerate(lines, start=1):\n",
    "    print(f\"Saved line {i} to {os.path.join(output_directory, f'line_{i}.png')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"These are possible ways to better process images\"\"\"\n",
    "\"\"\"visual bert needs more configuring\"\"\"\n",
    "https://huggingface.co/daki97/visualbert_finetuned_easy_vqa\n",
    "https://huggingface.co/docs/transformers/model_doc/visual_bert#overview # overview is part of the url, not a comment\n",
    "https://github.com/huggingface/transformers/blob/main/examples/research_projects/visual_bert/demo.ipynb\n",
    "\"\"\"layout needs more configuring\"\"\"\n",
    "https://huggingface.co/docs/transformers/model_doc/layoutlmv3\n",
    "\"\"\"should work for extracting printed text, but only works for single lines\"\"\"\n",
    "https://huggingface.co/microsoft/trocr-base-printed\n",
    "\"\"\"suggestions on how to split into multiple lines\"\"\"\n",
    "https://github.com/microsoft/unilm/issues/628\n",
    "https://discuss.huggingface.co/t/trocr-fine-tuning/13293/3\n",
    "\"\"\"vision encoder requires more configuration\"\"\"\n",
    "https://huggingface.co/docs/transformers/model_doc/vision-encoder-decoder\n",
    "\"\"\"Generate LaTEX from images\"\"\"\n",
    "https://huggingface.co/Norm/nougat-latex-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Import packages\"\"\"\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject of the Ai project\n",
      "\n",
      "\n",
      "Ai\n",
      "Species\n",
      "chimpanzee\n",
      "Born\n",
      "c.\n",
      " 1976\n",
      " (age \n",
      "46–47)\n",
      "Guinean Forests of West Africa\n",
      "Offspring\n",
      "Ayumu (chimpanzee)\n",
      "\n",
      "\n",
      "Ai\n",
      " (born in 1976, estimated) is a female \n",
      "western chimpanzee\n",
      " (\n",
      "Pan troglodytes verus\n",
      "),\n",
      "[1]\n",
      " currently living at the \n",
      "Primate Research Institute\n",
      " of \n",
      "Kyoto University\n",
      " (acronym KUPRI). She is the first subject of the \n",
      "Ai project\n",
      ", a research program started in 1978 by Kiyoko Murofushi and \n",
      "Tetsuro Matsuzawa\n",
      " which is aimed at understanding chimpanzee \n",
      "cognition\n",
      " through computer interface experiments.\n",
      "[2]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Biography\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "Ai was born in 1976 (estimated), in the \n",
      "Guinean Forests of West Africa\n",
      ".\n",
      "[1]\n",
      " Born wild, Ai was soon taken into captivity and sold to KUPRI in 1977 by an animal trader (this type of sale became illegal in 1980 with \n",
      "Japan\n",
      "'s ratification of \n",
      "CITES\n",
      ").\n",
      "[1]\n",
      "  She was the first subject of KUPRI’s chimpanzee project, which was intended to become Japan’s first ape-language study in the vein of earlier ape-language studies.\n",
      "[2]\n",
      " Ai was joined at KUPRI the following year by two more chimpanzees, Akira and Mari.\n",
      "[3]\n",
      " In 2000, Ai gave birth to a son, \n",
      "Ayumu\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "Ai Project\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "Matsuzawa has written that the difference between the Ai Project and earlier ape-language studies is that he was less interested in seeing if Ai and the other chimpanzees were capable of learning some degree of human language than trying to understand how chimpanzees perceive their surroundings.\n",
      "[2]\n",
      " To study this, the research team created a unique keyboard through which Ai and the other chimpanzees at KUPRI could interact with a computer –– the computer was used to standardize the studies and reduce variation that might be introduced by human researchers, and because the mechanism could be easily used in comparative studies on humans.\n",
      "[1]\n",
      " With this method, researchers have studied Ai’s memory, number-learning, and perception of color. Matsuzawa wrote that Ai was “the first chimpanzee who learned to use Arabic numerals to represent numbers,” and her ordering of different shades and hues of \n",
      "Munsell color chips\n",
      " was similar to human orderings.\n",
      "[2]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Group and living quarters\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "In 2000, not long after the birth of three chimpanzees, Ai's group numbered 15;\n",
      "[1]\n",
      " in 2010, there were 14 members.\n",
      "[4]\n",
      " This is similar to the size of some small chimpanzee groups in the wild, where in some places with stable food supplies group size hovers at around 20 chimpanzees.\n",
      "[5]\n",
      " Matsuzawa has attempted to blend elements of laboratory and field research, and KUPRI has an outdoor complex for the chimpanzees called the Ape Research Annex, built in 1995, with an 8-meter tall tower, a river, and trees.\n",
      "[3]\n",
      "\n",
      "\n",
      "\n",
      "After Ai gave birth to her son, Ayumu, in 2000, they were placed in a “twin booth” where Ayumu could live with Ai in one booth but also be exposed to the researcher in the other booth every day, making the researcher an integral part of Ayumu’s life and studying him in front of Ai, with her implicit approval.\n",
      "[6]\n",
      " Matsuzawa wrote that:\n",
      "Two almost identical booths are placed side by side. There is a door between the two booths that can alternately be opened to connect the two areas, closed to separate the two individuals, or positioned half-open to allow the young chimpanzee to crawl from one area to the other while preventing the mother chimpanzee from entering the neighboring booth.\n",
      "[6]\n",
      "This method allowed the research team to consistently track Ayumu's development without interfering excessively with the mother-offspring relationship.\n",
      "\n",
      "Art\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "Ai loves to paint and draw –– she started drawing at a young age –– and is often brought art materials for free-drawing or painting.\n",
      "[6]\n",
      " She creates art as an end in itself, without a food reward. In 2013 she made a painting that was given to the president of Kyoto University; later, in honor of the 40th anniversary of her arrival at KUPRI, this painting was made into a silk scarf and given as a gift to \n",
      "Jane Goodall\n",
      ".\n",
      "[6]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "See also\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "Primate Research Institute\n",
      "\n",
      "\n",
      "Great ape language\n",
      "\n",
      "\n",
      "List of individual apes\n",
      "\n",
      "\n",
      "References\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^ \n",
      "a\n",
      " \n",
      "b\n",
      " \n",
      "c\n",
      " \n",
      "d\n",
      " \n",
      "e\n",
      " \n",
      "Matsuzawa, Tetsuro (2003-12-01). \n",
      "\"The Ai project: historical and ecological contexts\"\n",
      ". \n",
      "Animal Cognition\n",
      ". \n",
      "6\n",
      " (4): 199–211. \n",
      "doi\n",
      ":\n",
      "10.1007/s10071-003-0199-2\n",
      ". \n",
      "ISSN\n",
      " \n",
      "1435-9448\n",
      ". \n",
      "PMID\n",
      " \n",
      "14566577\n",
      ". \n",
      "S2CID\n",
      " \n",
      "8928490\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^ \n",
      "a\n",
      " \n",
      "b\n",
      " \n",
      "c\n",
      " \n",
      "d\n",
      " \n",
      "Matsuzawa, Tetsuro (October 2009). \n",
      "\"The chimpanzee mind: in search of the evolutionary roots of the human mind\"\n",
      ". \n",
      "Animal Cognition\n",
      ". \n",
      "12\n",
      " (S1): S1-9. \n",
      "doi\n",
      ":\n",
      "10.1007/s10071-009-0277-1\n",
      ". \n",
      "ISSN\n",
      " \n",
      "1435-9448\n",
      ". \n",
      "PMID\n",
      " \n",
      "19727864\n",
      ". \n",
      "S2CID\n",
      " \n",
      "7028415\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^ \n",
      "a\n",
      " \n",
      "b\n",
      " \n",
      "\"Ai | Chimpanzee Ai | Primate Research Institute, Kyoto University\"\n",
      ". \n",
      "langint.pri.kyoto-u.ac.jp\n",
      ". Retrieved \n",
      "2020-10-24\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^\n",
      " \n",
      "\"Thinking Like a Chimpanzee\"\n",
      ". \n",
      "Smithsonian Magazine\n",
      ". Retrieved \n",
      "2020-10-24\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^\n",
      " \n",
      "Neal Webb, Sarah J.; Hau, Jann; Schapiro, Steven J. (January 2019). \n",
      "\"Does group size matter? Captive chimpanzee ( Pan troglodytes ) behavior as a function of group size and composition\"\n",
      ". \n",
      "American Journal of Primatology\n",
      ". \n",
      "81\n",
      " (1): e22947. \n",
      "doi\n",
      ":\n",
      "10.1002/ajp.22947\n",
      ". \n",
      "PMC\n",
      " \n",
      "6472487\n",
      ". \n",
      "PMID\n",
      " \n",
      "30620093\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^ \n",
      "a\n",
      " \n",
      "b\n",
      " \n",
      "c\n",
      " \n",
      "d\n",
      " \n",
      "Matsuzawa, Tetsuro (April 2017). \n",
      "\"The 40th anniversary of the Ai Project: the commemorative gift is a silk scarf painted by Ai the chimpanzee\"\n",
      ". \n",
      "Primates\n",
      ". \n",
      "58\n",
      " (2): 261–265. \n",
      "doi\n",
      ":\n",
      "10.1007/s10329-017-0604-0\n",
      ". \n",
      "ISSN\n",
      " \n",
      "0032-8332\n",
      ". \n",
      "PMID\n",
      " \n",
      "28293756\n",
      ". \n",
      "S2CID\n",
      " \n",
      "3635041\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "External links\n",
      "[\n",
      "edit\n",
      "]\n",
      "\n",
      "\n",
      "Ai's \n",
      "Official website\n",
      "\n",
      "\n",
      "v\n",
      "t\n",
      "e\n",
      "Notable non-human \n",
      "apes\n",
      "List of individual apes\n",
      "List of individual monkeys\n",
      "Monkeys and apes in space\n",
      "List of fictional primates\n",
      "Bonobos\n",
      "\n",
      "\n",
      "Kanzi\n",
      "\n",
      "\n",
      "Nyota\n",
      "\n",
      "\n",
      "Panbanisha\n",
      "\n",
      "\n",
      "Chimpanzees\n",
      "\n",
      "\n",
      "Ai\n",
      "\n",
      "\n",
      "Ayumu\n",
      "\n",
      "\n",
      "Azalea\n",
      "\n",
      "\n",
      "Bonzo\n",
      "\n",
      "\n",
      "Pierre Brassau\n",
      "\n",
      "\n",
      "Bubbles\n",
      "\n",
      "\n",
      "Cheeta\n",
      "\n",
      "\n",
      "Congo\n",
      "\n",
      "\n",
      "Enos\n",
      "\n",
      "\n",
      "Gregoire\n",
      "\n",
      "\n",
      "Gua\n",
      "\n",
      "\n",
      "Ham\n",
      "\n",
      "\n",
      "Jiggs\n",
      "\n",
      "\n",
      "Jimmy\n",
      "\n",
      "\n",
      "Jinx\n",
      "\n",
      "\n",
      "Jo Mendi II\n",
      "\n",
      "\n",
      "Julius\n",
      "\n",
      "\n",
      "Kasakela chimpanzee community\n",
      "\n",
      "\n",
      "Kokomo Jr.\n",
      "\n",
      "\n",
      "Lana\n",
      "\n",
      "\n",
      "Little Mama\n",
      "\n",
      "\n",
      "Loulis\n",
      "\n",
      "\n",
      "Lucy\n",
      "\n",
      "\n",
      "Macaco Tião\n",
      "\n",
      "\n",
      "Marquis Chimps\n",
      "\n",
      "\n",
      "Mitumba chimpanzee community\n",
      "\n",
      "\n",
      "Moja\n",
      "\n",
      "\n",
      "J. Fred Muggs\n",
      "\n",
      "\n",
      "Nim Chimpsky\n",
      "\n",
      "\n",
      "Oliver\n",
      "\n",
      "\n",
      "Pankun\n",
      "\n",
      "\n",
      "Panpanzee\n",
      "\n",
      "\n",
      "Sami\n",
      "\n",
      "\n",
      "Santino\n",
      "\n",
      "\n",
      "Sarah\n",
      "\n",
      "\n",
      "Sultan\n",
      "\n",
      "\n",
      "Travis\n",
      "\n",
      "\n",
      "Viki\n",
      "\n",
      "\n",
      "Washoe\n",
      "\n",
      "\n",
      "Gorillas\n",
      "\n",
      "\n",
      "Alfred the Gorilla\n",
      "\n",
      "\n",
      "Babec\n",
      "\n",
      "\n",
      "Binti Jua\n",
      "\n",
      "\n",
      "Bobo\n",
      "\n",
      "\n",
      "Bokito\n",
      "\n",
      "\n",
      "Charles the Gorilla\n",
      "\n",
      "\n",
      "Colo\n",
      "\n",
      "\n",
      "Fatou\n",
      "\n",
      "\n",
      "Gargantua\n",
      "\n",
      "\n",
      "Guy the Gorilla\n",
      "\n",
      "\n",
      "Harambe\n",
      "\n",
      "\n",
      "Ivan\n",
      "\n",
      "\n",
      "Jambo\n",
      "\n",
      "\n",
      "Jenny\n",
      "\n",
      "\n",
      "John Daniel\n",
      "\n",
      "\n",
      "Jumoke\n",
      "\n",
      "\n",
      "Koko\n",
      "\n",
      "\n",
      "Kokomo\n",
      "\n",
      "\n",
      "Louis\n",
      "\n",
      "\n",
      "Massa\n",
      "\n",
      "\n",
      "Max\n",
      "\n",
      "\n",
      "Michael\n",
      "\n",
      "\n",
      "Nico\n",
      "\n",
      "\n",
      "Ndume\n",
      "\n",
      "\n",
      "Ozzie\n",
      "\n",
      "\n",
      "Pattycake\n",
      "\n",
      "\n",
      "Pogo\n",
      "\n",
      "\n",
      "Samson\n",
      "\n",
      "\n",
      "Shabani\n",
      "\n",
      "\n",
      "Snowflake\n",
      "\n",
      "\n",
      "Timmy\n",
      "\n",
      "\n",
      "Titus\n",
      "\n",
      "\n",
      "Trudy\n",
      "\n",
      "\n",
      "Toto\n",
      "\n",
      "\n",
      "Willie B.\n",
      "\n",
      "\n",
      "Orangutans\n",
      "\n",
      "\n",
      "Abang\n",
      "\n",
      "\n",
      "Ah Meng\n",
      "\n",
      "\n",
      "Azy\n",
      "\n",
      "\n",
      "Bonnie\n",
      "\n",
      "\n",
      "Chantek\n",
      "\n",
      "\n",
      "Jenny\n",
      "\n",
      "\n",
      "Joe Martin\n",
      "\n",
      "\n",
      "Karen\n",
      "\n",
      "\n",
      "Karta\n",
      "\n",
      "\n",
      "Ken Allen\n",
      "\n",
      "\n",
      "Manis\n",
      "\n",
      "\n",
      "Nonja (Austria)\n",
      "\n",
      "\n",
      "Nonja (Malaysia)\n",
      "\n",
      "\n",
      "Sam\n",
      "\n",
      "\n",
      "Sandra\n",
      "\n",
      "\n",
      "Tonda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieved from \"\n",
      "https://en.wikipedia.org/w/index.php?title=Ai_(chimpanzee)&oldid=1178197952\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Scrape Wikipedia as a possible source of context\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_wikipedia_article(url):\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the main article text (adjust the selector based on the structure of the webpage)\n",
    "        article_text = soup.find('div', {'id': 'mw-content-text'}).get_text(separator='\\n')\n",
    "        \n",
    "        return article_text\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "url = 'https://en.wikipedia.org/wiki/Ai_(chimpanzee)'\n",
    "wikipedia_article_text = scrape_wikipedia_article(url)\n",
    "\n",
    "if wikipedia_article_text:\n",
    "    print(wikipedia_article_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat whose pictures went viral for regularly visiting a railway station is releasing a Christmas single. Four-year-old Nala has been delighting commuters who have been taking photos of her at Stevenage station. Owner Natasha Ambler revealed the cat was releasing a single called Meow and has been approached for a book deal. The ginger tabby has also recorded a video for the song due to be released this week, under the name Nala the Station Cat. It has been produced by Danny Kirsch, who wrote it with Joe Killington, while Nala is also co-credited as a songwriter, as well as a vocalist. Ms Ambler said \"we want to spread the happiness that Stevenage has had, and she's had on socials to the world\". The single is officially released on Wednesday and BBC Three Counties Radio's Justin Dealey gave the single an exclusive first play on Sunday. \"I'm slightly lost for words,\" said the presenter after the song finished. Nala's owner replied: \"So am I to be fair.\" The musical cat does not yet have an agent and her owner said \"we're all doing our emails ourselves; it's quite new to us\". \"We'll start small and hopefully she gets in the charts, but number one would be fantastic,\" she added. Charity campaigners LadBaby have filled the coveted Christmas number one single spot every year for the last five years. All proceeds from the single will be donated to the RSPCA and Stevenage homelessness charity Feed Up Warm Up. The music video, filmed at Stevenage railway station, will be unveiled before Christmas. Follow East of England news on Facebook, Instagram and X. Got a story? Email eastofenglandnews@bbc.co.uk or WhatsApp 0800 169 1830\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Scrape BBC as a possible source of context\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_bbc_article(url):\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the main article text (adjust the selector based on the structure of the webpage)\n",
    "        article = []\n",
    "        for para in soup.find_all(\"div\", {\"data-component\": \"text-block\"}):\n",
    "            article.append(para.text)\n",
    "        article_text = \" \".join(article)\n",
    "        \n",
    "        return article_text\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example usage - cat article\n",
    "url = 'https://www.bbc.co.uk/news/uk-england-beds-bucks-herts-67407334'\n",
    "bbc_article_text = scrape_bbc_article(url).replace('\\n', ' ')\n",
    "\n",
    "# Example questions - cat article\n",
    "bbc_cat_questions = ['Where will profit go?','Who produced the song?','What is the song called?',\\\n",
    "             'Who gave the song its first play?','When will the song be released?','Who wrote the song?',\\\n",
    "             'Where was the video filmed?','How has nala been delighting commuters?',\\\n",
    "             \"Who's pictures went viral?\", 'All proceeds from the single will be what?', 'What links Danny and Joe?']\n",
    "\n",
    "if bbc_article_text:\n",
    "    print(bbc_article_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retraining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da91f8a9279849ffb4b269e6c860b796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:37:16.271633: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-12-01 16:37:16.292324: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-12-01 16:37:16.292539: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (george-ThinkPad-X220-Tablet): /proc/driver/nvidia/version does not exist\n",
      "2023-12-01 16:37:17.115447: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "2023-12-01 16:37:17.564863: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "2023-12-01 16:37:17.660538: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "2023-12-01 16:37:20.262567: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['qa_outputs.bias', 'roberta.embeddings.position_ids', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "question_answerer_train = TFAutoModelForSequenceClassification.from_pretrained('deepset/roberta-base-squad2', from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answerer_train."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
