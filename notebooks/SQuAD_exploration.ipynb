{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a951bda",
   "metadata": {},
   "source": [
    "# Exploring the SQuAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa77e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"squad_v2\")\n",
    "\n",
    "explore_df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "text = explore_df.head(1)[\"context\"][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efacc1d",
   "metadata": {},
   "source": [
    "# Build a `keras` transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b22e80",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "473120ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_nlp.layers import TokenAndPositionEmbedding\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da856b48",
   "metadata": {},
   "source": [
    "## Building vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26342256",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = explore_df[\"context\"].unique()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb236d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum context length, in words\n",
    "max_len = max([len(context.split()) for context in context_list])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39a3ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2afccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 15:36:27.660001: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-11-27 15:36:27.660054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: rob-laptop\n",
      "2023-11-27 15:36:27.660062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: rob-laptop\n",
      "2023-11-27 15:36:27.660154: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.129.3\n",
      "2023-11-27 15:36:27.660178: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.129.3\n",
      "2023-11-27 15:36:27.660184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.129.3\n"
     ]
    }
   ],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    "    standardize = \"lower\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_len,\n",
    "\n",
    ")\n",
    "vectorize_layer.adapt(context_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1badde74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorize_layer.get_vocabulary()\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "653315ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '',\n",
       " 1: '[UNK]',\n",
       " 2: 'the',\n",
       " 3: 'in',\n",
       " 4: 'and',\n",
       " 5: 'of',\n",
       " 6: 'a',\n",
       " 7: 'to',\n",
       " 8: 'her',\n",
       " 9: 'beyoncé',\n",
       " 10: 'on',\n",
       " 11: 'was',\n",
       " 12: 'for',\n",
       " 13: 'with',\n",
       " 14: 'his',\n",
       " 15: 'at',\n",
       " 16: 'as',\n",
       " 17: 'she',\n",
       " 18: 'he',\n",
       " 19: 'that',\n",
       " 20: 'by',\n",
       " 21: 'from',\n",
       " 22: 'which',\n",
       " 23: 'chopin',\n",
       " 24: 'first',\n",
       " 25: 'music',\n",
       " 26: 'their',\n",
       " 27: 'an',\n",
       " 28: 'also',\n",
       " 29: 'had',\n",
       " 30: 'album',\n",
       " 31: 'is',\n",
       " 32: 'has',\n",
       " 33: 'best',\n",
       " 34: \"beyoncé's\",\n",
       " 35: 'one',\n",
       " 36: 'after',\n",
       " 37: 'it',\n",
       " 38: 'most',\n",
       " 39: 'i',\n",
       " 40: 'this',\n",
       " 41: 'song',\n",
       " 42: 'two',\n",
       " 43: 'released',\n",
       " 44: 'who',\n",
       " 45: 'million',\n",
       " 46: 'during',\n",
       " 47: 'new',\n",
       " 48: 'its',\n",
       " 49: 'artist',\n",
       " 50: 'were',\n",
       " 51: 'single',\n",
       " 52: 'other',\n",
       " 53: 'have',\n",
       " 54: 'second',\n",
       " 55: 'billboard',\n",
       " 56: 'solo',\n",
       " 57: 'performed',\n",
       " 58: 'not',\n",
       " 59: 'jay',\n",
       " 60: \"destiny's\",\n",
       " 61: \"chopin's\",\n",
       " 62: 'would',\n",
       " 63: 'where',\n",
       " 64: 'when',\n",
       " 65: 'video',\n",
       " 66: 'number',\n",
       " 67: 'piano',\n",
       " 68: 'made',\n",
       " 69: 'group',\n",
       " 70: 'concert',\n",
       " 71: 'became',\n",
       " 72: 'be',\n",
       " 73: 'all',\n",
       " 74: 'they',\n",
       " 75: 'songs',\n",
       " 76: 'received',\n",
       " 77: 'musical',\n",
       " 78: '2013,',\n",
       " 79: '100',\n",
       " 80: 'while',\n",
       " 81: 'three',\n",
       " 82: 'r&b',\n",
       " 83: 'performance',\n",
       " 84: 'june',\n",
       " 85: 'including',\n",
       " 86: 'grammy',\n",
       " 87: 'award',\n",
       " 88: 'april',\n",
       " 89: 'won',\n",
       " 90: 'sand',\n",
       " 91: 'paris',\n",
       " 92: 'him',\n",
       " 93: 'female',\n",
       " 94: 'february',\n",
       " 95: 'z',\n",
       " 96: 'year',\n",
       " 97: 'wrote',\n",
       " 98: 'third',\n",
       " 99: 'some',\n",
       " 100: 'september',\n",
       " 101: 'sasha',\n",
       " 102: 'mother',\n",
       " 103: 'later',\n",
       " 104: 'awards',\n",
       " 105: 'are',\n",
       " 106: 'american',\n",
       " 107: 'warsaw',\n",
       " 108: 'may',\n",
       " 109: 'many',\n",
       " 110: 'french',\n",
       " 111: 'following',\n",
       " 112: 'earned',\n",
       " 113: 'child',\n",
       " 114: 'but',\n",
       " 115: 'world',\n",
       " 116: 'op.',\n",
       " 117: 'more',\n",
       " 118: 'march',\n",
       " 119: 'major',\n",
       " 120: 'family',\n",
       " 121: 'cover',\n",
       " 122: 'awards,',\n",
       " 123: 'album,',\n",
       " 124: 'years',\n",
       " 125: 'us',\n",
       " 126: 'time',\n",
       " 127: 'said',\n",
       " 128: 'polish',\n",
       " 129: 'number-one',\n",
       " 130: 'named',\n",
       " 131: 'fryderyk',\n",
       " 132: 'debut',\n",
       " 133: 'composer',\n",
       " 134: 'been',\n",
       " 135: 'women',\n",
       " 136: 'woman',\n",
       " 137: 'top',\n",
       " 138: 'than',\n",
       " 139: 'studio',\n",
       " 140: 'six',\n",
       " 141: 'singles',\n",
       " 142: 'or',\n",
       " 143: 'only',\n",
       " 144: 'october',\n",
       " 145: 'my',\n",
       " 146: 'met',\n",
       " 147: 'love',\n",
       " 148: 'january',\n",
       " 149: 'house',\n",
       " 150: 'hot',\n",
       " 151: 'five',\n",
       " 152: 'film,',\n",
       " 153: 'film',\n",
       " 154: 'fashion',\n",
       " 155: 'become',\n",
       " 156: 'announced',\n",
       " 157: 'about',\n",
       " 158: '\"i',\n",
       " 159: 'year,',\n",
       " 160: 'tour',\n",
       " 161: 'took',\n",
       " 162: 'them',\n",
       " 163: 'such',\n",
       " 164: 'sold',\n",
       " 165: 'set',\n",
       " 166: 'release',\n",
       " 167: 'played',\n",
       " 168: 'placed',\n",
       " 169: 'over',\n",
       " 170: 'mtv',\n",
       " 171: 'list',\n",
       " 172: 'letter',\n",
       " 173: 'ladies',\n",
       " 174: 'inspired',\n",
       " 175: 'gave',\n",
       " 176: 'featured',\n",
       " 177: 'chopin,',\n",
       " 178: 'both',\n",
       " 179: 'association',\n",
       " 180: 'am...',\n",
       " 181: '2014,',\n",
       " 182: '2011,',\n",
       " 183: 'you',\n",
       " 184: 'well',\n",
       " 185: 'warsaw,',\n",
       " 186: 'soundtrack',\n",
       " 187: \"sand's\",\n",
       " 188: 'relationship',\n",
       " 189: 'records',\n",
       " 190: 'record',\n",
       " 191: 'published',\n",
       " 192: 'own',\n",
       " 193: 'november',\n",
       " 194: 'million.',\n",
       " 195: 'magazine',\n",
       " 196: 'love\",',\n",
       " 197: 'live',\n",
       " 198: 'liszt',\n",
       " 199: 'into',\n",
       " 200: 'included',\n",
       " 201: 'having',\n",
       " 202: 'further',\n",
       " 203: 'four',\n",
       " 204: 'found',\n",
       " 205: 'end',\n",
       " 206: 'do',\n",
       " 207: 'described',\n",
       " 208: 'copies',\n",
       " 209: 'composed',\n",
       " 210: 'campaign',\n",
       " 211: \"b'day\",\n",
       " 212: 'awards.',\n",
       " 213: 'among',\n",
       " 214: 'although',\n",
       " 215: 'age',\n",
       " 216: '2010,',\n",
       " 217: '\"the',\n",
       " 218: '\"single',\n",
       " 219: '\"crazy',\n",
       " 220: 'work',\n",
       " 221: 'up',\n",
       " 222: 'throughout',\n",
       " 223: 'super',\n",
       " 224: 'star',\n",
       " 225: 'singing',\n",
       " 226: 'singer',\n",
       " 227: 'since',\n",
       " 228: 'show',\n",
       " 229: 'several',\n",
       " 230: 'saw',\n",
       " 231: 'role',\n",
       " 232: 'ring',\n",
       " 233: 'return',\n",
       " 234: 'recorded',\n",
       " 235: 'public',\n",
       " 236: 'paris,',\n",
       " 237: 'no',\n",
       " 238: 'national',\n",
       " 239: 'maria',\n",
       " 240: 'listed',\n",
       " 241: 'line',\n",
       " 242: 'july',\n",
       " 243: 'inspiration',\n",
       " 244: 'however,',\n",
       " 245: 'fourth',\n",
       " 246: 'forbes',\n",
       " 247: 'couple',\n",
       " 248: 'concerts',\n",
       " 249: 'celebrity',\n",
       " 250: 'began',\n",
       " 251: 'before',\n",
       " 252: 'becoming',\n",
       " 253: 'attended',\n",
       " 254: 'atop',\n",
       " 255: 'artists',\n",
       " 256: 'appeared',\n",
       " 257: '4',\n",
       " 258: '2010',\n",
       " 259: '2009',\n",
       " 260: '(put',\n",
       " 261: '–',\n",
       " 262: 'york',\n",
       " 263: 'written',\n",
       " 264: 'worldwide',\n",
       " 265: 'works',\n",
       " 266: 'whose',\n",
       " 267: 'whom',\n",
       " 268: 'vocal',\n",
       " 269: 'visited',\n",
       " 270: 'us.',\n",
       " 271: 'united',\n",
       " 272: 'tour,',\n",
       " 273: 'time.',\n",
       " 274: 'spent',\n",
       " 275: 'signed',\n",
       " 276: 'same',\n",
       " 277: 'previously',\n",
       " 278: 'pop',\n",
       " 279: 'piano,',\n",
       " 280: 'per',\n",
       " 281: 'people',\n",
       " 282: 'part',\n",
       " 283: 'original',\n",
       " 284: 'nominated',\n",
       " 285: 'never',\n",
       " 286: 'name',\n",
       " 287: 'music,',\n",
       " 288: 'making',\n",
       " 289: 'little',\n",
       " 290: 'like',\n",
       " 291: 'life',\n",
       " 292: 'lead',\n",
       " 293: 'launched',\n",
       " 294: 'late',\n",
       " 295: 'last',\n",
       " 296: 'lady',\n",
       " 297: 'knowles',\n",
       " 298: 'influenced',\n",
       " 299: 'include',\n",
       " 300: 'great',\n",
       " 301: 'george',\n",
       " 302: 'fierce',\n",
       " 303: 'early',\n",
       " 304: 'debuted',\n",
       " 305: 'days',\n",
       " 306: 'dangerously',\n",
       " 307: 'dance',\n",
       " 308: 'continued',\n",
       " 309: 'contemporary',\n",
       " 310: 'commercial',\n",
       " 311: 'clothing',\n",
       " 312: 'chart.',\n",
       " 313: 'bowl',\n",
       " 314: 'blue',\n",
       " 315: 'best-selling',\n",
       " 316: 'being',\n",
       " 317: 'band',\n",
       " 318: 'annual',\n",
       " 319: '4,',\n",
       " 320: '2013',\n",
       " 321: '2008,',\n",
       " 322: '2',\n",
       " 323: 'writing',\n",
       " 324: 'world,',\n",
       " 325: 'what',\n",
       " 326: 'voice',\n",
       " 327: 'u.s.',\n",
       " 328: 'time,',\n",
       " 329: 'through',\n",
       " 330: 'then',\n",
       " 331: 'success',\n",
       " 332: 'streaming',\n",
       " 333: 'stores',\n",
       " 334: 'still',\n",
       " 335: 'stated',\n",
       " 336: 'started',\n",
       " 337: 'stage',\n",
       " 338: 'soul',\n",
       " 339: 'so',\n",
       " 340: 'should',\n",
       " 341: 'service',\n",
       " 342: 'school',\n",
       " 343: 'rock',\n",
       " 344: 'returned',\n",
       " 345: 'recording',\n",
       " 346: 'reached',\n",
       " 347: 'publicly',\n",
       " 348: 'pleyel',\n",
       " 349: 'playing',\n",
       " 350: 'play',\n",
       " 351: 'performing',\n",
       " 352: 'palace',\n",
       " 353: 'often',\n",
       " 354: 'no.',\n",
       " 355: 'michelle',\n",
       " 356: 'me',\n",
       " 357: 'marriage',\n",
       " 358: 'letters',\n",
       " 359: 'led',\n",
       " 360: 'launch',\n",
       " 361: 'introduced',\n",
       " 362: 'houston,',\n",
       " 363: 'himself',\n",
       " 364: 'hiller,',\n",
       " 365: 'herself',\n",
       " 366: 'health',\n",
       " 367: 'greatest',\n",
       " 368: 'giving',\n",
       " 369: 'friends',\n",
       " 370: 'featuring',\n",
       " 371: 'father',\n",
       " 372: 'established',\n",
       " 373: 'embarked',\n",
       " 374: 'destiny',\n",
       " 375: 'critics',\n",
       " 376: 'credits',\n",
       " 377: 'consecutive',\n",
       " 378: 'company',\n",
       " 379: 'child.',\n",
       " 380: 'child,',\n",
       " 381: 'career',\n",
       " 382: 'born',\n",
       " 383: 'birth',\n",
       " 384: 'between',\n",
       " 385: 'appearance',\n",
       " 386: 'any',\n",
       " 387: 'along',\n",
       " 388: 'according',\n",
       " 389: '2012,',\n",
       " 390: '2012',\n",
       " 391: '2011',\n",
       " 392: '2009,',\n",
       " 393: '2006,',\n",
       " 394: '2005,',\n",
       " 395: '200,',\n",
       " 396: '1',\n",
       " 397: '...',\n",
       " 398: 'years,',\n",
       " 399: 'year.',\n",
       " 400: 'worldwide.',\n",
       " 401: \"world's\",\n",
       " 402: 'works,',\n",
       " 403: 'without',\n",
       " 404: 'winning',\n",
       " 405: 'way',\n",
       " 406: 'visit',\n",
       " 407: 'very',\n",
       " 408: 'used',\n",
       " 409: 'under',\n",
       " 410: 'too',\n",
       " 411: 'these',\n",
       " 412: 'there',\n",
       " 413: 'talent',\n",
       " 414: 'take',\n",
       " 415: 'suffered',\n",
       " 416: 'style',\n",
       " 417: 'starring',\n",
       " 418: 'st.',\n",
       " 419: 'songs,',\n",
       " 420: 'song,',\n",
       " 421: 'social',\n",
       " 422: 'sister',\n",
       " 423: 'single,',\n",
       " 424: 'saying',\n",
       " 425: 'salle',\n",
       " 426: 'sales',\n",
       " 427: 'rue',\n",
       " 428: 'rowland',\n",
       " 429: 'romantic',\n",
       " 430: 'roberson',\n",
       " 431: 'revealed',\n",
       " 432: 'raised',\n",
       " 433: 'produced',\n",
       " 434: 'previous',\n",
       " 435: 'post',\n",
       " 436: 'poland',\n",
       " 437: 'pianist',\n",
       " 438: 'person',\n",
       " 439: 'performer',\n",
       " 440: 'pepsi',\n",
       " 441: 'past',\n",
       " 442: 'particularly',\n",
       " 443: 'paris.',\n",
       " 444: 'parents',\n",
       " 445: 'others',\n",
       " 446: 'order',\n",
       " 447: 'opposite',\n",
       " 448: 'numerous',\n",
       " 449: 'nine',\n",
       " 450: 'nicolas',\n",
       " 451: 'musician',\n",
       " 452: 'moved',\n",
       " 453: 'months',\n",
       " 454: 'member',\n",
       " 455: 'mathew',\n",
       " 456: 'main',\n",
       " 457: 'love,',\n",
       " 458: 'love\"',\n",
       " 459: \"liszt's\",\n",
       " 460: 'list,',\n",
       " 461: 'known',\n",
       " 462: 'how',\n",
       " 463: 'hit',\n",
       " 464: 'hip',\n",
       " 465: 'high',\n",
       " 466: 'hiatus',\n",
       " 467: 'helped',\n",
       " 468: 'held',\n",
       " 469: 'heat',\n",
       " 470: 'grossed',\n",
       " 471: 'global',\n",
       " 472: 'friend',\n",
       " 473: 'finally',\n",
       " 474: 'festival',\n",
       " 475: 'family,',\n",
       " 476: 'ever',\n",
       " 477: 'europe',\n",
       " 478: 'english',\n",
       " 479: 'endorsement',\n",
       " 480: 'earning',\n",
       " 481: 'dress',\n",
       " 482: 'deréon,',\n",
       " 483: 'depression',\n",
       " 484: 'death',\n",
       " 485: 'de',\n",
       " 486: 'day',\n",
       " 487: 'daughter',\n",
       " 488: \"couple's\",\n",
       " 489: 'concerto',\n",
       " 490: 'collection',\n",
       " 491: 'collaboration',\n",
       " 492: 'charity',\n",
       " 493: 'box',\n",
       " 494: 'black',\n",
       " 495: 'benefit',\n",
       " 496: 'because',\n",
       " 497: 'based',\n",
       " 498: 'around',\n",
       " 499: 'america',\n",
       " 500: 'alongside',\n",
       " 501: 'album.',\n",
       " 502: 'african-american',\n",
       " 503: 'actress',\n",
       " 504: 'able',\n",
       " 505: '5,',\n",
       " 506: '26',\n",
       " 507: '2015.',\n",
       " 508: '2014.',\n",
       " 509: '2008',\n",
       " 510: '2002,',\n",
       " 511: '2001,',\n",
       " 512: '1832',\n",
       " 513: '15',\n",
       " 514: '&',\n",
       " 515: '\"say',\n",
       " 516: '\"a',\n",
       " 517: 'z,',\n",
       " 518: 'young',\n",
       " 519: 'yet',\n",
       " 520: 'woyciechowski,',\n",
       " 521: 'words',\n",
       " 522: 'winter',\n",
       " 523: 'will',\n",
       " 524: 'went',\n",
       " 525: 'weeks',\n",
       " 526: 'week',\n",
       " 527: 'wall',\n",
       " 528: 'vogue',\n",
       " 529: 'version',\n",
       " 530: 'various',\n",
       " 531: 'use',\n",
       " 532: 'unique',\n",
       " 533: 'tweets',\n",
       " 534: 'tribute',\n",
       " 535: 'track',\n",
       " 536: 'tour.',\n",
       " 537: 'topshop',\n",
       " 538: 'together',\n",
       " 539: 'titled',\n",
       " 540: 'tina',\n",
       " 541: 'those',\n",
       " 542: 'themes',\n",
       " 543: 'texas,',\n",
       " 544: 'term',\n",
       " 545: 'technique',\n",
       " 546: 'teamed',\n",
       " 547: 'teaching',\n",
       " 548: 'supporting',\n",
       " 549: 'supported',\n",
       " 550: 'successful',\n",
       " 551: 'success.',\n",
       " 552: 'strong',\n",
       " 553: 'states.',\n",
       " 554: 'starred',\n",
       " 555: 'songwriter',\n",
       " 556: 'songs.',\n",
       " 557: 'son',\n",
       " 558: 'society',\n",
       " 559: 'shows',\n",
       " 560: 'sex',\n",
       " 561: 'seventh',\n",
       " 562: 'seven',\n",
       " 563: 'selling',\n",
       " 564: 'sand.',\n",
       " 565: 'salons',\n",
       " 566: 'rosen',\n",
       " 567: 'revel',\n",
       " 568: 'respect',\n",
       " 569: 'range',\n",
       " 570: 'r&b/soul',\n",
       " 571: 'r&b,',\n",
       " 572: 'producer',\n",
       " 573: 'private',\n",
       " 574: 'prince',\n",
       " 575: 'presented',\n",
       " 576: 'praise',\n",
       " 577: 'popular',\n",
       " 578: 'poor',\n",
       " 579: 'polonaises,',\n",
       " 580: 'polonaise',\n",
       " 581: 'polish,',\n",
       " 582: 'poland,',\n",
       " 583: 'pieces',\n",
       " 584: 'phoenix',\n",
       " 585: 'period',\n",
       " 586: 'performances,',\n",
       " 587: 'performances',\n",
       " 588: 'party',\n",
       " 589: 'parkwood',\n",
       " 590: 'parisian',\n",
       " 591: 'outstanding',\n",
       " 592: 'opened',\n",
       " 593: 'online',\n",
       " 594: 'nomination',\n",
       " 595: 'nohant,',\n",
       " 596: 'nights',\n",
       " 597: 'native',\n",
       " 598: 'name\"',\n",
       " 599: 'music.',\n",
       " 600: 'mrs.',\n",
       " 601: 'modern',\n",
       " 602: 'minor',\n",
       " 603: 'millennium',\n",
       " 604: 'mendelssohn',\n",
       " 605: 'married',\n",
       " 606: 'marie',\n",
       " 607: 'mariah',\n",
       " 608: 'management',\n",
       " 609: 'majorca',\n",
       " 610: 'madonna',\n",
       " 611: 'ludwika',\n",
       " 612: 'luckett',\n",
       " 613: 'lived',\n",
       " 614: 'literary',\n",
       " 615: 'liszt,',\n",
       " 616: 'list.',\n",
       " 617: 'life,',\n",
       " 618: 'lessons',\n",
       " 619: 'leading',\n",
       " 620: 'latter',\n",
       " 621: 'la',\n",
       " 622: 'kelly',\n",
       " 623: 'kazimierz',\n",
       " 624: 'just',\n",
       " 625: 'julian',\n",
       " 626: 'jealousy',\n",
       " 627: 'jay-z',\n",
       " 628: 'james',\n",
       " 629: 'jackson',\n",
       " 630: 'it)\",',\n",
       " 631: 'intimate',\n",
       " 632: 'influences',\n",
       " 633: 'industry',\n",
       " 634: 'image',\n",
       " 635: 'if',\n",
       " 636: 'history',\n",
       " 637: 'hill',\n",
       " 638: 'highly',\n",
       " 639: 'highest-paid',\n",
       " 640: 'help',\n",
       " 641: 'group.',\n",
       " 642: 'grossing',\n",
       " 643: 'golden',\n",
       " 644: 'given',\n",
       " 645: 'girls',\n",
       " 646: \"girl's\",\n",
       " 647: 'get',\n",
       " 648: 'generally',\n",
       " 649: 'frequently',\n",
       " 650: 'franz',\n",
       " 651: 'france',\n",
       " 652: 'fragrance,',\n",
       " 653: 'former',\n",
       " 654: 'fifth',\n",
       " 655: 'fierce,',\n",
       " 656: 'few',\n",
       " 657: 'felix',\n",
       " 658: 'father,',\n",
       " 659: 'fame',\n",
       " 660: 'expressed',\n",
       " 661: 'exploring',\n",
       " 662: 'etta',\n",
       " 663: 'estimated',\n",
       " 664: 'entertainment',\n",
       " 665: 'elementary',\n",
       " 666: 'elder',\n",
       " 667: 'eight',\n",
       " 668: 'efforts.',\n",
       " 669: 'education',\n",
       " 670: 'earnings',\n",
       " 671: 'earlier',\n",
       " 672: 'duo',\n",
       " 673: 'duchy',\n",
       " 674: 'dreamgirls',\n",
       " 675: 'donated',\n",
       " 676: 'does',\n",
       " 677: 'displayed',\n",
       " 678: 'deréon.',\n",
       " 679: 'deréon',\n",
       " 680: 'dedicated',\n",
       " 681: 'deal',\n",
       " 682: 'critics,',\n",
       " 683: 'critic',\n",
       " 684: 'created',\n",
       " 685: 'course',\n",
       " 686: 'could',\n",
       " 687: 'considered',\n",
       " 688: 'conservatory,',\n",
       " 689: 'compositions',\n",
       " 690: 'composition.',\n",
       " 691: 'comedy',\n",
       " 692: 'close',\n",
       " 693: \"child's\",\n",
       " 694: 'chart,',\n",
       " 695: 'chart',\n",
       " 696: 'celebrities',\n",
       " 697: 'carter',\n",
       " 698: 'career,',\n",
       " 699: 'can',\n",
       " 700: 'campaign,',\n",
       " 701: 'called',\n",
       " 702: 'cadillac',\n",
       " 703: 'break',\n",
       " 704: 'beyoncé,',\n",
       " 705: 'believe',\n",
       " 706: 'bad',\n",
       " 707: 'back',\n",
       " 708: 'autumn',\n",
       " 709: 'august,',\n",
       " 710: 'artistic',\n",
       " 711: 'arrived',\n",
       " 712: 'anthem',\n",
       " 713: 'albums',\n",
       " 714: \"album's\",\n",
       " 715: 'adjacent',\n",
       " 716: 'acting',\n",
       " 717: '7,',\n",
       " 718: '24,',\n",
       " 719: '21',\n",
       " 720: '2015,',\n",
       " 721: '2015',\n",
       " 722: '2013.',\n",
       " 723: '2012.',\n",
       " 724: '2011.',\n",
       " 725: '2007,',\n",
       " 726: '2006',\n",
       " 727: '2003,',\n",
       " 728: '20',\n",
       " 729: '1990s',\n",
       " 730: '1847',\n",
       " 731: '1842',\n",
       " 732: '1837',\n",
       " 733: '1835',\n",
       " 734: '1830',\n",
       " 735: '1810,',\n",
       " 736: '17',\n",
       " 737: '10',\n",
       " 738: '(in',\n",
       " 739: '(a',\n",
       " 740: '\"love',\n",
       " 741: '\"listen\"',\n",
       " 742: '\"irreplaceable\"',\n",
       " 743: '\"déjà',\n",
       " 744: '\"drunk',\n",
       " 745: 'Żywny,',\n",
       " 746: 'Études,',\n",
       " 747: 'zeitung',\n",
       " 748: 'zamoyski',\n",
       " 749: \"z's\",\n",
       " 750: 'your',\n",
       " 751: 'youngest',\n",
       " 752: 'younger',\n",
       " 753: 'years.',\n",
       " 754: \"year's\",\n",
       " 755: 'wrote,',\n",
       " 756: \"writing's\",\n",
       " 757: 'woyciechowski',\n",
       " 758: 'worldwide,',\n",
       " 759: 'worked',\n",
       " 760: 'work,',\n",
       " 761: 'word',\n",
       " 762: 'women.',\n",
       " 763: 'wodzińska,',\n",
       " 764: 'win',\n",
       " 765: 'williams.',\n",
       " 766: 'wilhelm',\n",
       " 767: 'wife',\n",
       " 768: 'white',\n",
       " 769: 'west',\n",
       " 770: 'week,',\n",
       " 771: 'weather',\n",
       " 772: 'wearing',\n",
       " 773: 'wealthy',\n",
       " 774: 'wax',\n",
       " 775: 'washington,',\n",
       " 776: \"warsaw's\",\n",
       " 777: 'want',\n",
       " 778: 'vu\",',\n",
       " 779: 'vocals.',\n",
       " 780: 'vocals',\n",
       " 781: 'visitors',\n",
       " 782: 'visiting',\n",
       " 783: 'vh1',\n",
       " 784: 'variations',\n",
       " 785: 'using',\n",
       " 786: 'uses',\n",
       " 787: 'us,',\n",
       " 788: 'urging',\n",
       " 789: 'uprising',\n",
       " 790: 'upon',\n",
       " 791: 'until',\n",
       " 792: 'university,',\n",
       " 793: 'unhappy',\n",
       " 794: 'unexpectedly',\n",
       " 795: 'ultimately',\n",
       " 796: 'tsar',\n",
       " 797: 'true',\n",
       " 798: 'travelled',\n",
       " 799: 'traveled',\n",
       " 800: 'training',\n",
       " 801: 'traditional',\n",
       " 802: 'track,',\n",
       " 803: 'total',\n",
       " 804: 'toronto',\n",
       " 805: 'topped',\n",
       " 806: 'top\"',\n",
       " 807: 'together.',\n",
       " 808: 'title',\n",
       " 809: 'times',\n",
       " 810: 'time\"',\n",
       " 811: 'tied',\n",
       " 812: 'tidal.',\n",
       " 813: 'tidal,',\n",
       " 814: 'things',\n",
       " 815: 'them.',\n",
       " 816: 'ten',\n",
       " 817: 'talented',\n",
       " 818: 'taking',\n",
       " 819: 'szafarnia',\n",
       " 820: \"swift's\",\n",
       " 821: 'survivor',\n",
       " 822: 'support',\n",
       " 823: 'summers',\n",
       " 824: 'subsequent',\n",
       " 825: 'styles.',\n",
       " 826: 'style,',\n",
       " 827: 'student,',\n",
       " 828: 'student',\n",
       " 829: 'street',\n",
       " 830: 'strange',\n",
       " 831: 'story',\n",
       " 832: 'store',\n",
       " 833: 'stone',\n",
       " 834: 'status',\n",
       " 835: 'state',\n",
       " 836: 'start',\n",
       " 837: 'stage,',\n",
       " 838: 'stadium',\n",
       " 839: 'sportswear,',\n",
       " 840: 'sports',\n",
       " 841: 'spokesperson',\n",
       " 842: 'split',\n",
       " 843: 'speculation',\n",
       " 844: 'specialty',\n",
       " 845: 'speak',\n",
       " 846: 'spanish',\n",
       " 847: 'south',\n",
       " 848: 'soon',\n",
       " 849: 'sony',\n",
       " 850: 'songwriting',\n",
       " 851: \"solange's\",\n",
       " 852: 'solange',\n",
       " 853: 'skin',\n",
       " 854: 'sixth',\n",
       " 855: 'singles;',\n",
       " 856: 'singles,',\n",
       " 857: 'shown',\n",
       " 858: 'showed',\n",
       " 859: \"she's\",\n",
       " 860: 'sharon',\n",
       " 861: 'sexiest',\n",
       " 862: 'settled',\n",
       " 863: 'sent',\n",
       " 864: 'seeing',\n",
       " 865: 'schumann,',\n",
       " 866: 'says',\n",
       " 867: 'saxon',\n",
       " 868: 'sand,',\n",
       " 869: 'said,',\n",
       " 870: 'russian',\n",
       " 871: 'runs',\n",
       " 872: 'ruler',\n",
       " 873: 'rowland,',\n",
       " 874: 'rolling',\n",
       " 875: 'roles',\n",
       " 876: 'robert',\n",
       " 877: 'rita',\n",
       " 878: 'rihanna,',\n",
       " 879: 'reviews',\n",
       " 880: 'retailer',\n",
       " 881: 'response',\n",
       " 882: 'research',\n",
       " 883: 'reported',\n",
       " 884: 'remain',\n",
       " 885: 'relief',\n",
       " 886: 'releases',\n",
       " 887: 'released.',\n",
       " 888: 'relationship.',\n",
       " 889: 'rehearsing',\n",
       " 890: 'records.',\n",
       " 891: 'recording,',\n",
       " 892: 'recognized',\n",
       " 893: 'recital',\n",
       " 894: 'receiving',\n",
       " 895: 'really',\n",
       " 896: 'ranked',\n",
       " 897: 'radio',\n",
       " 898: 'r&b/hip-hop',\n",
       " 899: 'qualities',\n",
       " 900: 'put',\n",
       " 901: 'pupil',\n",
       " 902: 'publishing',\n",
       " 903: 'provides',\n",
       " 904: 'proposed',\n",
       " 905: 'prompted',\n",
       " 906: 'promote',\n",
       " 907: 'professional',\n",
       " 908: 'productive',\n",
       " 909: 'produce',\n",
       " 910: 'problems',\n",
       " 911: 'presidential',\n",
       " 912: 'president',\n",
       " 913: 'presents:',\n",
       " 914: 'present',\n",
       " 915: 'presence',\n",
       " 916: 'premiered',\n",
       " 917: 'preludes',\n",
       " 918: 'pregnant',\n",
       " 919: 'pregnancy',\n",
       " 920: 'pre-recorded',\n",
       " 921: 'praised',\n",
       " 922: 'powers',\n",
       " 923: 'powerful',\n",
       " 924: 'power',\n",
       " 925: 'portrayal',\n",
       " 926: 'portrait',\n",
       " 927: 'portmanteau',\n",
       " 928: 'pop,',\n",
       " 929: 'political',\n",
       " 930: 'pleyel,',\n",
       " 931: 'plays',\n",
       " 932: 'play,',\n",
       " 933: 'pink',\n",
       " 934: 'pictures',\n",
       " 935: 'piano.',\n",
       " 936: 'phase',\n",
       " 937: 'personally',\n",
       " 938: 'period.',\n",
       " 939: 'performances.',\n",
       " 940: 'perform',\n",
       " 941: 'peaking',\n",
       " 942: 'panther',\n",
       " 943: 'palace.',\n",
       " 944: 'out,',\n",
       " 945: 'out',\n",
       " 946: 'other,',\n",
       " 947: 'originally',\n",
       " 948: 'organization',\n",
       " 949: 'organ,',\n",
       " 950: 'opera',\n",
       " 951: 'open',\n",
       " 952: 'officially',\n",
       " 953: 'official',\n",
       " 954: 'office',\n",
       " 955: 'occasionally',\n",
       " 956: 'obtained',\n",
       " 957: \"obama's\",\n",
       " 958: 'obama',\n",
       " 959: 'now',\n",
       " 960: 'noted',\n",
       " 961: 'northern',\n",
       " 962: 'north',\n",
       " 963: 'nominations',\n",
       " 964: 'nohant',\n",
       " 965: 'no,',\n",
       " 966: 'no\".',\n",
       " 967: 'nicki',\n",
       " 968: 'news',\n",
       " 969: 'networking',\n",
       " 970: 'names',\n",
       " 971: 'name.',\n",
       " 972: 'naacp',\n",
       " 973: 'musikalische',\n",
       " 974: 'musicians',\n",
       " 975: 'music\".',\n",
       " 976: 'museums',\n",
       " 977: 'movie',\n",
       " 978: 'move',\n",
       " 979: 'motion',\n",
       " 980: 'mother,',\n",
       " 981: \"mother's\",\n",
       " 982: 'month.',\n",
       " 983: 'month,',\n",
       " 984: 'money',\n",
       " 985: 'moment',\n",
       " 986: 'moderate',\n",
       " 987: 'mobile',\n",
       " 988: 'missy',\n",
       " 989: 'miscarriage',\n",
       " 990: 'minute.',\n",
       " 991: 'minor,',\n",
       " 992: 'minaj',\n",
       " 993: 'michael',\n",
       " 994: 'methodist',\n",
       " 995: 'mention',\n",
       " 996: 'men',\n",
       " 997: 'members',\n",
       " 998: 'media',\n",
       " 999: 'martin,',\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_lookup = dict(zip(range(len(vocab)), vocab))\n",
    "index_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2c46dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beyoncé',\n",
       " 'giselle',\n",
       " 'knowles-carter',\n",
       " '(/biːˈjɒnseɪ/',\n",
       " 'bee-yon-say)',\n",
       " '(born',\n",
       " 'september',\n",
       " '4,',\n",
       " '1981)',\n",
       " 'is',\n",
       " 'an',\n",
       " 'american',\n",
       " 'singer,',\n",
       " 'songwriter,',\n",
       " 'record',\n",
       " 'producer',\n",
       " 'and',\n",
       " 'actress.',\n",
       " 'born',\n",
       " 'and',\n",
       " 'raised',\n",
       " 'in',\n",
       " 'houston,',\n",
       " 'texas,',\n",
       " 'she',\n",
       " 'performed',\n",
       " 'in',\n",
       " 'various',\n",
       " 'singing',\n",
       " 'and',\n",
       " 'dancing',\n",
       " 'competitions',\n",
       " 'as',\n",
       " 'a',\n",
       " 'child,',\n",
       " 'and',\n",
       " 'rose',\n",
       " 'to',\n",
       " 'fame',\n",
       " 'in',\n",
       " 'the',\n",
       " 'late',\n",
       " '1990s',\n",
       " 'as',\n",
       " 'lead',\n",
       " 'singer',\n",
       " 'of',\n",
       " 'r&b',\n",
       " 'girl-group',\n",
       " \"destiny's\",\n",
       " 'child.',\n",
       " 'managed',\n",
       " 'by',\n",
       " 'her',\n",
       " 'father,',\n",
       " 'mathew',\n",
       " 'knowles,',\n",
       " 'the',\n",
       " 'group',\n",
       " 'became',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " \"world's\",\n",
       " 'best-selling',\n",
       " 'girl',\n",
       " 'groups',\n",
       " 'of',\n",
       " 'all',\n",
       " 'time.',\n",
       " 'their',\n",
       " 'hiatus',\n",
       " 'saw',\n",
       " 'the',\n",
       " 'release',\n",
       " 'of',\n",
       " \"beyoncé's\",\n",
       " 'debut',\n",
       " 'album,',\n",
       " 'dangerously',\n",
       " 'in',\n",
       " 'love',\n",
       " '(2003),',\n",
       " 'which',\n",
       " 'established',\n",
       " 'her',\n",
       " 'as',\n",
       " 'a',\n",
       " 'solo',\n",
       " 'artist',\n",
       " 'worldwide,',\n",
       " 'earned',\n",
       " 'five',\n",
       " 'grammy',\n",
       " 'awards',\n",
       " 'and',\n",
       " 'featured',\n",
       " 'the',\n",
       " 'billboard',\n",
       " 'hot',\n",
       " '100',\n",
       " 'number-one',\n",
       " 'singles',\n",
       " '\"crazy',\n",
       " 'in',\n",
       " 'love\"',\n",
       " 'and',\n",
       " '\"baby',\n",
       " 'boy\".',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_as_tokens = vectorize_layer(context_list[0])\n",
    "translated_back = [index_lookup[token] for token in sentence_as_tokens.numpy().tolist()]\n",
    "translated_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "153a9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokenized = [vectorize_layer(context) for context in context_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec87c3b",
   "metadata": {},
   "source": [
    "## Creating masked tokens & targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "274ac0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y_creator(sequence_tensor):\n",
    "    # tile / copy the input sequence up to max_len -1\n",
    "    tiled_sequence = tf.tile(tf.expand_dims(sequence_tensor, 0), [max_len - 1, 1])\n",
    "    # use band_part to diagonally mask the sequence of tensors, so that there is a sequence of incremental strings\n",
    "    X_s = tf.linalg.band_part(tiled_sequence, -1, 0)\n",
    "    # y is simply the next word in the sequence\n",
    "    y_s = sequence_tensor[1:]\n",
    "    return X_s, y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6c8cd4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = []\n",
    "ys = []\n",
    "for sequence in all_tokenized:\n",
    "    X, y = X_y_creator(sequence)\n",
    "    Xs.append(X)\n",
    "    ys.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0b3673e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(325, 326), dtype=int64, numpy=\n",
       "array([[   9,    0,    0, ...,    0,    0,    0],\n",
       "       [   9, 1115,    0, ...,    0,    0,    0],\n",
       "       [   9, 1115, 2598, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   9, 1115, 2598, ...,    0,    0,    0],\n",
       "       [   9, 1115, 2598, ...,    0,    0,    0],\n",
       "       [   9, 1115, 2598, ...,    0,    0,    0]])>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d7bd4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2d tensor for X - this will have shape ((max_len - 1) * n_sequences, max_len)\n",
    "X = tf.concat(Xs, axis = 0)\n",
    "# Create a 1d tensor for y - this will have shape (max_len - 1)\n",
    "y = tf.concat(ys, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c65ee4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(326,), dtype=int64, numpy=\n",
       "array([9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ed545979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any sequences where the next predicted y is 0 - ie, where the next predicted word is null.\n",
    "X = X[y != 0]\n",
    "y = y[y != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "af9827a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([13546])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "194dc016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([13546, 326])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0c214549",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimensions = 256\n",
    "\n",
    "inputs = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "x = TokenAndPositionEmbedding(vocab_size, max_len, embedding_dimensions, mask_zero=True)(inputs)\n",
    "x = layers.Dense(vocab_size, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(vocab_size, activation=\"relu\")(x)\n",
    "x = tf.reduce_mean(x, axis=1)\n",
    "outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f31c2c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 326)]             0         \n",
      "                                                                 \n",
      " token_and_position_embeddi  (None, 326, 256)          1158656   \n",
      " ng_17 (TokenAndPositionEmb                                      \n",
      " edding)                                                         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 326, 4200)         1079400   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 326, 4200)         0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 326, 4200)         17644200  \n",
      "                                                                 \n",
      " tf.math.reduce_mean_2 (TFO  (None, 4200)              0         \n",
      " pLambda)                                                        \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 4200)              17644200  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37526456 (143.15 MB)\n",
      "Trainable params: 37526456 (143.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0d206f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "424/424 [==============================] - 847s 2s/step - loss: 7.1955 - accuracy: 0.0574\n",
      "Epoch 2/10\n",
      "311/424 [=====================>........] - ETA: 3:52 - loss: 6.9102 - accuracy: 0.0619"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [144], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1779\u001b[0m if self.autotune_steps_per_execution:\n\u001b[1;32m   1780\u001b[0m     self._steps_per_execution_tuner.start()\n\u001b[1;32m   1781\u001b[0m # Handle fault-tolerance for multi-worker.\n\u001b[1;32m   1782\u001b[0m # TODO(omalleyt): Fix the ordering issues that mean this has to\n\u001b[0;32m-> 1783\u001b[0m # happen after `callbacks.on_train_begin`.\n\u001b[1;32m   1784\u001b[0m steps_per_epoch_inferred = (\n\u001b[1;32m   1785\u001b[0m     steps_per_epoch or data_handler.inferred_steps\n\u001b[1;32m   1786\u001b[0m )\n\u001b[1;32m   1787\u001b[0m (\n\u001b[1;32m   1788\u001b[0m     data_handler._initial_epoch,\n\u001b[1;32m   1789\u001b[0m     data_handler._initial_step,\n\u001b[1;32m   1790\u001b[0m ) = self._maybe_load_initial_counters_from_ckpt(\n\u001b[1;32m   1791\u001b[0m     steps_per_epoch_inferred, initial_epoch\n\u001b[1;32m   1792\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[1;32m    828\u001b[0m   \u001b[38;5;66;03m# TODO(cheshire): Do not duplicate the XLAControlFlowContext annotation.\u001b[39;00m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 831\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m    832\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    862\u001b[0m if self._created_variables:\n\u001b[1;32m    863\u001b[0m   # Release the lock early so that multiple threads can perform the call\n\u001b[1;32m    864\u001b[0m   # in parallel.\n\u001b[1;32m    865\u001b[0m   self._lock.release()\n\u001b[1;32m    866\u001b[0m   # In this case we have created variables on the first call, so we run the\n\u001b[0;32m--> 867\u001b[0m   # defunned version which is guaranteed to never create variables.\n\u001b[1;32m    868\u001b[0m   return tracing_compilation.call_function(\n\u001b[1;32m    869\u001b[0m       args, kwds, self._no_variable_creation_config\n\u001b[1;32m    870\u001b[0m   )\n\u001b[1;32m    871\u001b[0m elif self._variable_creation_config is not None:\n\u001b[1;32m    872\u001b[0m   # Release the lock early so that multiple threads can perform the call\n\u001b[1;32m    873\u001b[0m   # in parallel.\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1259\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1260\u001b[0m     function_type_utils\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m   1261\u001b[0m         args, kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type)\n\u001b[1;32m   1262\u001b[0m )\n\u001b[1;32m   1263\u001b[0m filtered_flat_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m-> 1264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m   1265\u001b[0m     filtered_flat_args,\n\u001b[1;32m   1266\u001b[0m     captured_inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m    216\u001b[0m flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m--> 252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, tensor_inputs, num_outputs):\n\u001b[1;32m   1477\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls the function associated with the given name.\"\"\"\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m   attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m-> 1479\u001b[0m       itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m   1480\u001b[0m           \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs()\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1481\u001b[0m       )\n\u001b[1;32m   1482\u001b[0m   )\n\u001b[1;32m   1484\u001b[0m   cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 60\u001b[0m   keras_symbolic_tensors \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs \u001b[38;5;28;01mif\u001b[39;00m _is_keras_symbolic_tensor(x)]\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m keras_symbolic_tensors:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_SymbolicException(\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs to eager execution function cannot be Keras symbolic \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensors, but found \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(keras_symbolic_tensors))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs = 10, workers= 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
